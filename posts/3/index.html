
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Wood Carver</title>
  <meta name="author" content="Wood Carver">

  
  <meta name="description" content="接触了一些message system的系统（大部分是kafka），对message queue的作用和关键点有了一些了解。这些就谈谈我的认识，和使用注意事项。 message queue的作用 查阅了材料发现总结下来，列举的理由有十几条之多，但是直接貌似没有任何联系和组织方式。很是不好理解。 &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://woodcarver.github.io/posts/3/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Wood Carver" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/libs/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<!-- link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css"-->
<!-- link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css"-->

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Wood Carver</a></h1>
  
    <h2>Find another pool</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="sitesearch" value="woodcarver.github.io">
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/book-links">Books</a></li>
  <li><a href="/about">About Me</a></li>
  <li><a href="/start-here">Start Here</a></li>
  <li><a href="/others-blog">Reading</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/04/10/how-to-understand-a-message-sysetm/">Message System</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-04-10T18:31:31+08:00'><span class='date'><span class='date-month'>Apr</span> <span class='date-day'>10</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>6:31 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>接触了一些message system的系统（大部分是kafka），对message queue的作用和关键点有了一些了解。这些就谈谈我的认识，和使用注意事项。</p>

<h1>message queue的作用</h1>

<p>查阅了材料发现总结下来，列举的理由有十几条之多，但是直接貌似没有任何联系和组织方式。很是不好理解。我在这里使用模型的变化来阐述我自己的理解：
<img src="./images/posts/message_system.png" alt="naive" />
从上面的演化图来看，有了消息队列后的一个本质变化就是把收消息和接消息的任务都扔给了第三方，其实这就是软件行业中最一般的做法如果要获得软件的灵活性和扩展性，那么就开始加中间层。计算机网络是这么做的，同样操作系统也是这么做的。
而考虑具体的好处这个问题和系统会出现什么问题是手心手背的关系。我们就来一块一块的说。
我们假设我们要做一个买票系统。数据库使用mysql，前面只有一个售票程序来操作数据。这时候的模型就是第一个模块的样子。初期的时候一切都很完美，这个网站只拥有1万用户，每天只卖500张票。
后来发现有些背后的mysql总是宕机，导致用户订票总是不成功，所以就想着怎么把用户的订单信息先存下来，然后等mysql恢复后马上继续处理。这时候你就开始想着建立一个消息缓存队列，然后程序自然形成了一个生产者消费者模型。同时你还会发现这个不仅仅有消息缓存的好处，还有发现消息现在是可以被保存了（或者说很便捷和自然的保存了）。以前那些因为程序bug处理失败的消息可以被重复处理了。还有就是哪天突然要在mysql之上加上一层redis，那其实也不必修改上游程序。总结下来：
1. 缓冲 &ndash; 消息的缓存，当下游处于宕机状态，消息可以被缓存等待重启后继续处理。
2. 解耦 &ndash; 项目之间解耦，形成各种微服务
3. 冗余
4. 送达保证
5. 顺序保证能实现了</p>

<p>再后来你的系统的用户增加到了100万，而且因为是买的火车票，所以一到过节订单就出现高峰，这时候辛亏你有了消息队列可以帮你缓存。
6. 消除峰值 &ndash; 即消息均衡，当消息的生产速度差距很大的时候，消息可以被缓存，然后转发其他空闲的服务上或者等待等后续措施。</p>

<p>后来再发现一个消息队列因为不够存储高峰期间储蓄的数据了，这时候再增加下游的消费者处理能力很浪费，因为平时你用不着。这时候发现增加一个消息队列服务的成本去很低，那么开始扩展这里。
7. 扩展性</p>

<p>其他feature：
1. 异步通信
这个是好是坏，全看实际的引用场景。对于实时要求性很高，但是不要求消息全部保证被处理就是无所谓的特性。</p>

<ol>
<li>附赠的feature(只是更方便吧)
因为消息缓存的独立，可以对其处理速度监控，从而得知系统的负载能力。</li>
</ol>


<p>从另一个角度再看看消息队列的作用：
因为从生产者、消费者两方关系衍生到生产者、消息队列、消费者三方之间的关系，所以我们就从3个主题的角度讨论。
1. 主体一生产者会发生些什么情况：</p>

<ul>
<li>性能——流量突然增大，或者流量是不均匀的</li>
<li>部分失效——突然部分生产者挂了。如果没有消息队列，那就意味着部分消费者没有任务消费了，或者消费者自己做了任务自动均衡，这是一件比较麻烦的额事情。</li>
<li>容错性——都挂了。如果没有消息队列，那么消费者也立即进入休息状态。但是有了消息对立后以前生产的东西还能储存下来，提供消费者消费，然后有个缓冲时间窗口重启</li>
<li>扩展性——突然要增加生产者的数量，没有消息队列的情况下，意味着需要有一套re-balance的机制在里面，同样时间麻烦的事情。统统都交给消息队列考虑吧。其实这条和部分失效是一样的，都是scaling过程。</li>
<li><p>复用（解耦）——生产的消息万一不仅仅只有一个消费者，这样还需要一套分发机制。也是件麻烦的事情。有了消息队列，其实消费者和我再也没啥关系了。我爱怎么生成就怎么生产。</p></li>
<li><p>主体二消费者会发生些什么情况：</p></li>
<li><p>性能——处理速度万一跟不上呢？</p></li>
<li>扩展性——同上，消息队列提供了扩展收缩自动均衡的策略。</li>
</ul>


<h1>如果学习一个message queue？</h1>

<h2>消息可达性保证机制</h2>

<p>这个机制或者约定更确切些，就是描述系统到底怎么client进行交互，确保信息是正确的到达了目的地。一般的消息保证机制有：
1. 至多一次，保证绝对不重复发，但是有丢数据情况。这种情况server处理是最简单的，发完了就不管了，不需要和client交互。</p>

<blockquote><p>at-most-once delivery means that for each message handed to the mechanism, that message is delivered zero or one times; in more casual terms it means that messages may be lost.
2. 至少一次，保证一定client接收到了信息，如果不能确定client接收到了信息会重复发。做到这点server只要一直发知道接收到了client的ack。
at-least-once delivery means that for each message handed to the mechanism potentially multiple attempts are made at delivering it, such that at least one succeeds; again, in more casual terms this means that messages may be duplicated but not lost.
3. 精确的一次，保证不重复发但也不丢数据。exactly-once是最难保证的，因为这涉及到通信中的很多情况。
exactly-once delivery means that for each message handed to the mechanism exactly one delivery is made to the recipient; the message can neither be lost nor duplicated.</p>

<p>The first one is the cheapest—highest performance, least implementation overhead—because it can be done in a fire-and-forget fashion without keeping state at the sending end or in the transport mechanism. The second one requires retries to counter transport losses, which means keeping state at the sending end and having an acknowledgement mechanism at the receiving end. The third is most expensive—and has consequently worst performance—because in addition to the second it requires state to be kept at the receiving end in order to filter out duplicate deliveries.</p></blockquote>

<h3>为什么保证不了消息发送？</h3>

<ol>
<li>The message is sent out on the network?</li>
<li>The message is received by the other host?</li>
<li>The message is put into the target actor&rsquo;s mailbox?</li>
<li>The message is starting to be processed by the target actor?</li>
<li>The message is processed successfully by the target actor?</li>
</ol>


<p>其实就从消息传递从出发到结果的整个过程，状体包括出发、路上、进门、喝茶、出门和回家通报。
其中在路上需要花多少时间谁都不知道，还有没有万一进门后被真“喝茶”后，不返回通报的你让发送者的家人怎么办？</p>

<h2>消息顺序保证机制</h2>

<ol>
<li>保证消息一定是顺序到达的，这个地方需要考虑如果是一个kafka的系统，同一个group下的不同consumer之间的顺序怎么保证？</li>
<li>不保证消息一定顺序到达</li>
</ol>


<h1>reference</h1>

<ol>
<li><a href="http://doc.akka.io/docs/akka/2.4.3/general/message-delivery-reliability.html">Message Delivery Reliability</a></li>
<li><a href="http://www.jasongj.com/2015/01/02/Kafka%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90/">Kafka深度解析</a></li>
</ol>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/03/25/a-bug-tracing/">A Bug Tracing</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-03-25T15:36:20+08:00'><span class='date'><span class='date-month'>Mar</span> <span class='date-day'>25</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>3:36 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content">
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/03/16/study-tree/">Study Tree</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-03-16T15:00:42+08:00'><span class='date'><span class='date-month'>Mar</span> <span class='date-day'>16</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>3:00 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>Java learning</h1>

<ol>
<li><p>基本语法
这包括static、final、transient等关键字的作用，foreach循环的原理，volatile等等。今天面试我问你static关键字有哪些作用，如果你答出static修饰变量、修饰方法我会认为你合格，答出静态块，我会认为你不错，答出静态内部类我会认为你很好，答出静态导包我会对你很满意，因为能看出你非常热衷研究技术。</p></li>
<li><p>数据结构（容器）
ArrayList、LinkedList、Hashtable、HashMap、ConcurrentHashMap、HashSet的实现原理,掌握CopyOnWrite容器和Queue, 特别是ConcuurentHashMap：
（1）ConcurrentHashMap的锁分段技术
（2）ConcurrentHashMap的读是否要加锁，为什么
（3）ConcurrentHashMap的迭代器是强一致性的迭代器还是弱一致性的迭代器</p></li>
<li><p>设计模式
（1）你的项目中用到了哪些设计模式，如何使用
（2）知道常用设计模式的优缺点
（3）能画出常用设计模式的UML图</p></li>
<li><p>多线程
Thread和Runnable的区别和联系、多次start一个线程会怎么样、线程有哪些状态
假如有Thread1、Thread2、Thread3、Thread4四条线程分别统计C、D、E、F四个盘的大小，所有线程都统计完毕交给Thread5线程去做汇总，应当如何实现？
另外，线程池也是比较常问的一块，常用的线程池有几种？这几种线程池之间有什么区别和联系？线程池的实现原理是怎么样的？实际一些的，会给你一些具体的场景，让你回答这种场景该使用什么样的线程池比较合适。
<a href="http://www.cnblogs.com/xrq730/p/5060921.html">40个java多线程问题总结</a></p></li>
<li><p>Jdk源码
（1）List、Map、Set实现类的源代码
（2）ReentrantLock、AQS的源代码
（3）AtomicInteger的实现原理，主要能说清楚CAS机制并且AtomicInteger是如何利用CAS</p></li>
<li><p>Java虚拟机
（1）Java虚拟机的内存布局
（2）GC算法及几种垃圾收集器
（3）类加载机制，也就是双亲委派模型
（4）Java内存模型
（5）happens-before规则
（6）volatile关键字使用规则</p></li>
</ol>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/03/15/how-is-lambda-created/">How Is Lambda Created?</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-03-15T14:16:01+08:00'><span class='date'><span class='date-month'>Mar</span> <span class='date-day'>15</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>2:16 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content">
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/02/29/introduce-kafka/">使用kafka</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-02-29T15:16:17+08:00'><span class='date'><span class='date-month'>Feb</span> <span class='date-day'>29</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>3:16 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>kafka是什么，解决了什么问题</h1>

<p>本质上kafka是一个消息订阅发布系统，当然这种系统设计的实现已经有千千万，kafka也只是其中的一个。所以要了解kafka，我们先看看什么消息订阅发布系统和这种设计是针对解决什么问题发被发明出来的。
消息发送模式一般有两种——点对点，广播，而相应的技术是队列和订阅发布。消息队列。
当然这里再提到关于一种消息队列也是数据库的观点（message queue is database too）， 所以从kafka的设计逻辑上它实际也是一个种管理数据获取和写入的系统。所以也可以从逻辑结构和储存结构两个方面来理解系统。参看<a href="./2016-07-24-how-to-understand-d-data-system">如何理解一个数据存储系统</a>。</p>

<p>而kafka的创始人则对kafka作为data pipeline中的一个real-time stream centre bus来设定，增加了分布式的特性(扩展性和容错性)，同时以低延迟高可用为一个重要设计目标。</p>

<p>还有一个特点，那就是kafka的写入和读取都是采用batch的模型。</p>

<h2>设计消息订阅发布系统的关键点在哪里？，参看<a href="./2016-04-10-message-delivery-reliability">如何理解一个消息系统</a></h2>

<h1>kafka处在hadoop生态圈的什么位置</h1>

<h1>kafka基本模型和优缺点</h1>

<ul>
<li>基于日志</li>
</ul>


<h1>如何生产消息</h1>

<p>关键词：topic, group, partition, offset
所有的消息系统在设计消息生产的时候都要考虑消息的<strong>时序性和可达性</strong>。</p>

<h2>在时序方面</h2>

<p>kafka在这方面保证在partition内是写入顺序。其中新接口给出了partition的指派自定义规则，一种是自己定义（Partitioner接口），另一种是通过其定义了一个消息体类ProducerRecord，是一个key-value格式，就是为了保证同样的key会被放入同样的parition上（注意这可能导致数据倾斜）。如果key被设置为null，那么parition指派规则就使用 default partitioner 规则—— Round-robin，随机分配。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;String, String&gt;("Country", "Precision Products", "France");</span></code></pre></td></tr></table></div></figure>


<p>至于当摸个partition突然失效，那么相应的key的message会怎么办？这个就是设计到了kafka的容错机制——replication and availability.</p>

<h2>可达性而言</h2>

<p>所有的可达性都需要客户端的配合才能形式要求的特性（at -most-once, at-least-once and exactly-once）。</p>

<p>现在有个大大的问题 —— 消息到底写没写成功？假如现在对消息的写入成功要求非常高，一定需要这件事情。所以客户端需要有个信号告诉这件事情，所以如果kafka告诉客户端写成功了，客户端就认为写成功了，然后进行下一条消息操作。</p>

<p>大多数人想想的都是这样的：</p>

<p><img src="https://img3.doubanio.com/view/photo/photo/public/p2375588550.jpg" alt="normal" />
这是最理想的情况，最麻烦就是出现异常情况，我们首先来列下那些异常会出现：</p>

<p>至少涉及到消息都会有两种状态，到达了和超时。</p>

<table>
<thead>
<tr>
<th> 情况  </th>
<th> 消息发送</th>
<th> 确认（ack）发送</th>
</tr>
</thead>
<tbody>
<tr>
<td>接收到反馈，反馈是成功</td>
<td>完事了</td>
<td> 完事</td>
</tr>
<tr>
<td>接收到反馈，反馈是失败</td>
<td>重写  </td>
<td> 重写</td>
</tr>
<tr>
<td>超时</td>
<td>？</td>
<td>？</td>
</tr>
</tbody>
</table>


<p>假如接收到反馈，反馈是失败，那么也很简单，那就是再重写一遍。
但是最复杂的情况就是ack超时的情况，以为超时可能有下面几种可能造成的：
<img src="https://img3.doubanio.com/view/photo/photo/public/p2375588551.jpg" alt="message loss" />
如果是信息丢失了，我可以重写如一遍嘛，好解决。但是如果是ack丢失了，按照上面添加的规则，<strong>信息重复了</strong>！重点还是这两种情况对于客户端来说是没办法区分的。这可以容忍就要看具体业务了？</p>

<p>从kafka的API看出，其消息是通过异步的Future类实现。要怎么处理消息的可达性的自主权其实完全交给了用户自己决定。包括storm也是这么做的。</p>

<p><img src="https://img3.doubanio.com/view/photo/photo/public/p2375588553.jpg" alt="message loss" /></p>

<p>具体实现方式通过kafka的Producer的配置：</p>

<ol>
<li><p>acks：描述接收broker的确认信息的机制。这个是一个int型，其数量描述的是有多少replica响应的acks（和replica的leader模型有关系）。当值为0的时候，表示不接受确认直接返回，也就是说不确认信息是否怎的写入了broker。意味着at-most-once模型。当然这种也是发送吞吐量最高的模型。
当acks=1时候，接收leader的acks响应。当然这种也有丢失数据的风险，当leader crash了或者当新leader被选中但是却没有这个消息的副本。
当acks = all，接收所有replica的确认信息。</p></li>
<li><p>retries：描述producer发送失败的时候，重试的次数。</p></li>
</ol>


<h1>如何消费消息</h1>

<p>关键词：topic, group, partition, offset</p>

<p>同样所有的消息系统在设计消息消费的时候都要考虑消息的<strong>时序性和可达性</strong>。而kafka的时序性则表现在<strong>partition内保持有序的，partition之间无序</strong>，这样也就是意味着一个partition在一个group只能被一个consumer消费。而不会出现一个partition对应多个consumer的现象。这个特性配合上producer可以指定写入partition的规则，能做很多序列化的事情。下面的图展示的是partition的数量和consumer数量各种情况下的模型：</p>

<h2>时序性</h2>

<ol>
<li><p>partition数量大于consumer数量：
<img src="https://img3.doubanio.com/view/photo/photo/public/p2375588545.jpg" alt="naive" /></p></li>
<li><p>partition数量等于consumer数量：
<img src="https://img1.doubanio.com/view/photo/photo/public/p2375588547.jpg" alt="naive" /></p></li>
<li><p>partition数量小于consumer数量：
<img src="https://img1.doubanio.com/view/photo/photo/public/p2375588548.jpg" alt="naive" />
看见有consumer开始轮空了。这个就是为了保证一个partition内的时序性。所以在扩展的时候需要保证partition数量大于consumer数量的，否则有些consumer就浪费了。</p></li>
</ol>


<h2>讲完时序性，现在开始讲可达性。</h2>

<p>kafka的消息可达性保证是通过committed offset这个机制实现的。什么是committed offset呢？</p>

<blockquote><p>We call the action of updating the current position in the partition a commit.</p></blockquote>

<p> 那就是在一个共享的地方更新每个partition的处理位置。即读的过程中告诉某个人（其实是通过__consumer_offsets这个特殊的topic实现的？怎么实现的？）我读到哪里了。但是这里有个问题就是回报和实现处理的步调可能不一致，然后到底怎么选择就看实际业务需求了。kafka提供了自动commit机制——定时回报offset，明显是异步。同时又提供了同步和异步commit的接口供使用。</p>

<ol>
<li>使用auto commit</li>
<li>使用同步commit</li>
<li>使用异步commit</li>
</ol>


<p>既然partition和consumer数量都是不限制的，那就会涉及到系统设计的核心问题——rescale(rebalance)。</p>

<h1>How to scale kafka?</h1>

<p>我们都知道在分布式储存系统是为了能够并行，必须做两件事情，一个是partition or sharding， 另一个是replica。当然kafka都做了，并且还提供了partition的显示调度接口。所以这个小节来看看kafka是怎么做parition的。</p>

<h1>消息本身 ——  消息的格式</h1>

<p>kafa的消息格式是规定好的二进制协议的，这点和redis的策略一样。所以客户端只要传输二进制流给服务端即可。因为这和语言无关，所以客户端可以采用任何一种语言，而不仅仅限于java。</p>

<blockquote><p>Kafka has a binary wire protocol. This means that it is possible for applications to read messages from Kafka or write messages to Kafka simply by sending the cor‐ rect byte sequences to Kafka’s network port. There are multiple cli‐ ents that implement Kafka’s wire protocol in different programming language, giving simple ways to use Kafka not just in Java applications but also in languages like C++, Python, Go and many more. Those clients are not part of Apache Kafka project, but a list of those is maintained in the project wiki 1. The wire protocol and the external clients are outside the scope of the chapter.</p></blockquote>

<h1>Replica设计</h1>

<p>kafka的replica的单元是partition而不是topic，而每个partition有一个leader和0到多个的followers。</p>

<p>As with most distributed systems automatically handling failures requires having a precise definition of what it means for a node to be &ldquo;alive&rdquo;. For Kafka node liveness has two conditions</p>

<ol>
<li>A node must be able to maintain its session with ZooKeeper (via ZooKeeper&rsquo;s heartbeat mechanism)</li>
<li>If it is a slave it must replicate the writes happening on the leader and not fall &ldquo;too far&rdquo; behind</li>
</ol>


<p>Kafka will remain available in the presence of node failures after a short fail-over period, but may not remain available in the presence of network partitions.</p>

<h1>设计巧妙的地方？</h1>

<ul>
<li><p>partition的设计非常巧妙</p>

<ol>
<li>和key绑定，相当于Bigtable中的raw key ，可以自由选择如何sharding数据。</li>
<li>partition内的时序性保证，解决了一些不能乱序的消息</li>
<li>rebalance（committed offset管理）, 当parition增加和减少的时候，如果rebalance consumer，当然如何rebalance producer（can？）？</li>
</ol>
</li>
<li><p>group的设计</p>

<ol>
<li>能够轻松的并行，并随意的扩展</li>
</ol>
</li>
<li><p>offset管理</p>

<ol>
<li>committed offset</li>
</ol>
</li>
<li><p>batch模式</p>

<ol>
<li>当然是为了加速</li>
</ol>
</li>
</ul>


<h1>reference</h1>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/02/22/notes-for-hadoop-the-defintive-guid/">Hadoop权威指南笔记</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-02-22T15:13:26+08:00'><span class='date'><span class='date-month'>Feb</span> <span class='date-day'>22</span><span class='date-suffix'>nd</span>, <span class='date-year'>2016</span></span> <span class='time'>3:13 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>阅读 <a href="http://blog.nosqlfan.com/html/744.html">MapReduce: A major step backwards</a></h1>

<p>这个是2014年图灵奖获得者Michael Stonebraker和David J. DeWitt。两位都是数据库界的领军人物。
下面主要介绍下文章对mapreduce提出的质疑和观点</p>

<h2>mapreduce的理念设计方面</h2>

<ul>
<li>在数据库Schema(结构和数据的关系)方面，破坏了40年的数据实践条律：

<ul>
<li>Schemas是有益的——没有schema的存在，数据可以被任意填充，所以会有很多的垃圾数据出现</li>
<li>将schema和程序分开处理是有益的——指mapreduce把数据结构都埋藏在代码中，非常不便与重复提出和维护</li>
<li>High-level存取语言是有益的——关系型数据库使用一种声明式存取方法，而不展现出存取的具体算法。而mapreduce直接把整个存取算法过程仍给使用者
这里主要是说mapreduce中的两个步骤都和应用紧密结合，可以填充任意操作</li>
</ul>
</li>
</ul>


<h2>mapreduce的实现方面</h2>

<ul>
<li>没有索引，所以所有搜索都是暴力的顺序搜索。</li>
<li>mapreduce的并行特性，早在19世界80年代就有成熟的商业产品，例如Teradata，Gamma等，和这些软件比起来mapreduce并没有特别突出的地方。</li>
<li>mapreduce的map阶段有数据倾斜的分线（skew，类似于一个二叉树中的非平衡情况，如果特别不平衡直接会使搜索退化成了顺序的）会直接降低并行的计算能力</li>
<li>mapreduce中的reduce获取map的结果方式使用的是pull（map的结果一般存放在map的本地机器上）,这是一个巨大的性能瓶颈。原文提出使用push paradigm代替pull paradigm，这个具体不太明白？</li>
</ul>


<h2>mapreduce概念一点都不新鲜</h2>

<h2>mapreduce缺乏现有数据库的关键特性,对终端使用者造成了很大困扰</h2>

<ul>
<li>Bulk loader — to transform input data in files into a desired format and load it into a DBMS</li>
<li>Indexing — as noted above</li>
<li>Updates — to change the data in the data base</li>
<li>Transactions — to support parallel update and recovery from failures during update</li>
<li>Integrity constraints — to help keep garbage out of the data base</li>
<li>Referential integrity — again, to help keep garbage out of the data base</li>
<li>Views — so the schema can change without having to rewrite the application program</li>
</ul>


<h2>mapreduce不兼容现有的DBMS工具</h2>

<ul>
<li>Report writers (e.g., Crystal reports) to prepare reports for human visualization</li>
<li>Business intelligence tools (e.g., Business Objects or Cognos) to enable ad-hoc querying of large data warehouses</li>
<li>Data mining tools (e.g., Oracle Data Mining or IBM DB2 Intelligent Miner) to allow a user to discover structure in large data sets</li>
<li>Replication tools (e.g., Golden Gate) to allow a user to replicate data from on DBMS to another</li>
<li>Database design tools (e.g., Embarcadero) to assist the user in constructing a data base.</li>
</ul>


<p>文章最后呼吁mapreduce的开发这了解最近25年内并行数据库文献，放下自以为是的态度，汲取40年的数据库发展经历和各方观点解决上面提出的问题。</p>

<p>这篇文章写的年代比较早，现在已经有了很多基于mapreduce的工具。比如hive，实现了很多现代数据库的很多特性。比如，物理数据结构和logical schame分离；提供方便的查询语言（一种类似SQL语言）；提供了Bulk loader工具。
当然hive只是在hadoop上建设了一层中间转层，提供了数据的逻辑结构，但是仍然不提供修改数据等功能等。这个和mysql等现有的关系性数据库从数据入库开始就做强约束的策略是不一样的。所以hive在写入文件是没有强约束的，而约束是只发生在读取数据时候。</p>

<h1>阅读 <a href="http://scienceblogs.com/goodmath/2008/01/22/databases-are-hammers-mapreduc/">Databases are hammers; MapReduce is a screwdriver</a></h1>

<p>文章上来就指出关系数据库的拥护者过于痴迷于这种完美的工具，以至于本末倒置的宁愿把螺丝当钉子使用，就因为有这么完美的锤子（指关系型数据库）在手。
接下来开始列车作者的观点：
- 关系型数据库不能很好并行运行
- 不能很好的处理非结构化数据
- 在处理内嵌结构数据上也背负恶名
<strong> MapReduce的目的不是用来取代Relation Ddatabase，而是祢补其缺点的，提供一种轻量级并行编程，解决另外一族计算问题。 </strong></p>

<p>这篇文章是回应上面那篇文章的，并一一针对上面的各种观点提出了自己的看法。
- 没有索引，所以所有搜索都是暴力的顺序搜索 —— 回应是：大多数大规模数据计算是使用不了关系数据模型在单机上进行的，且索引这种中心式结构很容易成为性能瓶颈，还有当计算是密集型的时候，索引是没有用的
- mapreduce缺乏现有数据库的关键特性 —— 回应是：难道不是关系型就是不好的吗？（两篇文章感觉火药味十足啊！）
- mapreduce不兼容现有的DBMS工具 —— 回应是：如果继续兼容现有DBMS，就想上面提到的为了使用锤子，而错把螺丝钉当钉子使用</p>

<h1>说了那么多，我们谈谈mapreduce是个什么东西</h1>

<p>mapreduce是一个分布式批量计算框架。想必听到这句话的时候大家应该和我一样会问计算框架是个什么东西，也有可能就是吓的不敢问了？
最粗的方式：
- map
- reduce</p>

<p>其次粒度，6个阶段：
- input ： 这个阶段注意输入格式
- split ：这个阶段注意split的性能
- map
- shuffle
- reduce ： 注意数据倾斜
- output ：注意输出格式</p>

<p>最细粒度：
- input
- split
- mapper
- combiner
- partitioner
到这里都是本地机器内操作
- shuffle
- reduce
- output</p>

<h2>一个mapreduce job的启动过程</h2>

<p>话说说完了计算框架的逻辑，那么要运行一个计算任务该怎么做？发现又是另一套东西，怎么都是感觉表面一套背地里一套！</p>

<h2>第一版的过程</h2>

<h2>为什么需要yarn？</h2>

<p>如果不是在大量环境中运行一段时候后，意识到了大量的问题后，估计每个人都会觉得上面的方案已经很完美了。所以这里先提出mapreduce框架的缺陷：
1. 我们都知道，只要是master结构的架构，随着需求的不断扩大瓶颈一般都会出在master身上，而JobTracker这个这个master。因为JobTracker的限制，所有的资源分配任务和监视任务都集中在Jobtracker上面。所有当集群特别大的时候，内存，cup等肯定会出现问题。
2. master结构还有一个问题，就是单点问题，加入master一挂，那么整个系统就挂了，这和分布式系统倡导高可用、容错特性背向而驰。而当集群越来越大，job越来愈多，都靠Jobtracker调度，那么其挂的可能性有增大的很多。
3. 不完美的不仅是Jobtracker，还有TaskTracker。问题就在于TaskTracker把资源强制划分为 map task slot 和 reduce task slot, 如果当系统中只有 map task 或者只有 reduce task 的时候，会造成资源的浪费，也就是前面提过的集群资源利用的问题。这样就会经常出现一个job的map任务都做完了，但是reduce阶段却获得不了资源而终止，很是浪费。
4. TaskTracker对任务的大小也没做考虑，有些任务大，有些任务小。假如两个都很占用内存的任务遇到一起，就会导致OOM，Task失败。</p>

<h2>编写mapreduce</h2>

<h3>万恶的数据倾斜</h3>

<ol>
<li>为什么会发生数据倾斜
根据上面mapreduce逻辑过程我们发现，数据倾斜不可能发生在map过程，都是发生在reduce过程。为什么呢？因为shuffle过程有个规则就是同样的key会发往同一个reduce上，所以到出现key1的记录条数是10亿，而key2的记录条数是10个，那么接到key1的reduce可就要倒霉了，同时其他的reduce也要陪着慢慢的等。</li>
</ol>


<p>怎么解决呢？（难道mapreduce自己没有解决机制吗？）</p>

<ul>
<li>既然出现大key的时候会出现倾斜，那么直接的解决方法就是把大key给拆了，可以通过加后缀的方式改变key值。</li>
</ul>


<h1>hadoop的另一大旗舰产品——HDFS</h1>

<h2>reference</h2>

<ul>
<li><a href="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-yarn/">Hadoop 新 MapReduce 框架 Yarn 详解</a></li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/02/17/deep-insight-of-linux-system-status-description-commands/">Linux系统状态命令详解</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-02-17T21:58:48+08:00'><span class='date'><span class='date-month'>Feb</span> <span class='date-day'>17</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>9:58 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>知识地图</h1>

<p>这篇文章整理的是对关于诊断linux系统状况的相关指标和命令。涉及到：</p>

<ol>
<li>I/O负载状况</li>
<li>进程控制</li>
<li>cpu负载状况</li>
<li>memory占用情况</li>
<li>网络状况</li>
<li>disk使用情况</li>
</ol>


<p>其中统计值会把I/O的时候见包含进cpu时间中，所以从上面的分类来看一个运行的进程的指标——cpu就是衡量任务的占时状况，而内存就是占用空间情况。</p>

<h1>Commands about I/O</h1>

<ul>
<li>什么是I/O</li>
</ul>


<p>再让我们看一眼csapp的那幅经典图
<img src="http://woodcarver.oss-cn-shanghai.aliyuncs.com/post/computer_organization.png" alt="computer organization" />
看到所有的设备都是通过I/O bridge把数据移动到Main memory上，然后再主存再和CPU交互进行计算。当CPU有输出时，也是先输出到主存上，然后再输入到设备上。而再计算机中I/O设备就只除去CPU和主存的设备，也成外围设备。
介绍完I/O设备，那什么是I/O呢？按照《Unix系统内幕》的定义：</p>

<blockquote><p>The I/O subsystem haldes the movement of data between memory and peripheral devices such as disks, printers, and terminals.
所以I/O就是指I/O设备和memory之间数据移动。</p></blockquote>

<p>怎么才算是一次I/O，大概是指移动次数但是这个不重要，重要的是对于I/O的衡量却不是根据其移动次数，而是根据其占用一个运行任务的时间比例衡量的。所以如果运行的进程中你看到真正使用CPU时间的比例很少，“大部分”是在等待I/O。那么就是说I/O不行，跟不上CPU的节奏。</p>

<p>那当发现I/O占时过大的时候怎么办？目标就是减少I/O！这个目标说起来容易，做起来也确实有几个常规方法。一种是数据库系统经常用到了。例如mysql的索引技术就是排除不相关数据，只传当前相关的数据。还有些对磁盘的数据进行压缩，这个传输到内存上的容量就少了，I/O自然降了。
还有就是换设备，换硬盘、换网卡<code>^_^</code>。</p>

<h2>iostat</h2>

<h2>top</h2>

<p>top对I/O的描述是用I/O wait这个指标，例如下图：
<img src="http://woodcarver.oss-cn-shanghai.aliyuncs.com/post/top_command_short.png" alt="top command" />
其中I/O wait 的定义是：</p>

<blockquote><p>I/O wait is the percentage of time your processors are waiting on the disk.
I/O wait就是CPU在整个任务处理中等待闲置的时间，举个例子：一个任务一共使用了1s，但是其中从从磁盘中取数据花了700ms，而在磁盘读取数据时CPU是闲置的，所以CPU的等待I/O的时间占了70%，即I/O wait 是70%。
当然有人指出对多核cpu通过iowait来统计io的负载情况并不准确，<a href="http://veithen.github.io/2013/11/18/iowait-linux.html">详见</a></p></blockquote>

<p><code>threshold：当I/O wait &gt; 1/CPU_cores 可以判断明显出现了I/O瓶颈(why?)。</code></p>

<h2>sar</h2>

<p>同样使用I/O wait这个指标，每10mini(默认时间间隔，可以调节)纪录一次系统状态值,保留一段时间的历史数据。</p>

<h2>dstat</h2>

<p>发现这个命令组合很有意思
dstat -tdD total,sda,sdb,sdc,md1 60</p>

<h1>command about CPU</h1>

<h2>top</h2>

<p>top对cpu的描述有下面几个值：
user &ndash; 表示用户太消耗的cpu时间
sys &ndash; 表示内核态消耗的cpu时间
real &ndash; 表示操作从开始到结束所经过的墙钟时间（Wall Clock Time）
cpu时间和墙钟时间的区别是，墙钟时间包括各种非运算的等待时间，例如等待磁盘I/O，等待线程阻塞，而cpu时间不包括这些耗时。但是当系统有多个cpu或者多核的时候，多线程操作会叠加这些cpu时间，所以如果看到user+sys > real 是正常的。</p>

<h2>Reference</h2>

<ul>
<li>[深入理解计算机系统（第二版）]</li>
<li>[Unix系统内幕]</li>
<li><a href="http://blog.scoutapp.com/articles/2011/02/10/understanding-disk-i-o-when-should-you-be-worried">understanding disk i/o - when should you be worried?</a></li>
<li><a href="http://veithen.github.io/2013/11/18/iowait-linux.html">The precise meaning of I/O wait time in Linux</a></li>
</ul>


<h1>进程控制</h1>

<ul>
<li>exec</li>
<li>source</li>
<li>kill</li>
<li>bg,fg,jobs</li>
<li>nice</li>
</ul>


<h1>网络状况</h1>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/01/26/introduce-thrift/">Introduce Thrift</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-01-26T14:46:14+08:00'><span class='date'><span class='date-month'>Jan</span> <span class='date-day'>26</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>2:46 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>History</h2>

<ul>
<li>诞生于facebook
facebook开源出的RPC开源框架，现在已经成为Apache的顶级项目。</li>
</ul>


<h2>Why need thrift</h2>

<p>This question can also be instead of another one&ndash;Is RPC service complicated?
Before I try to know distributed system, I don&rsquo;t know that it need using a book to make PRC clearly and RPC is an absolutly important skill requirement on service developing posistion.
If you want to know thrift, you must know RPC.</p>

<h2>What is RPC</h2>

<p>RPC的全称是Remote Procedure Call。这种类型的技术专注与格式化客户端和服务端传输，以实现更方便的远程交互，甚至能做到和本地调用无多大区别的程度。
整个过程是客户端发送RPC请求到服务端，服务端处理后再发结果反馈过来。听这很简单，看着很容易，而且很熟悉。这不就是cs模型吗？但是其中涉及的难点就隐藏在老生常谈的信息通信中。比如消息体的打包，拆分，解读等等。
目的就是保质保量的让消息正确抵达目的地。
读过计算机网络的都知道，如果一切都正常的话是最简单的情况，但是旁枝的异常情况和各种因素的权益会让系统复杂n倍。
涉及到通信就需要考虑到一下几个因素：</p>

<ol>
<li>时间性</li>
<li>顺序性</li>
<li>会发生丢失</li>
</ol>


<p>让我们来仔细列出这个动态系统的主题：</p>

<ol>
<li>client： 动作——request，receive</li>
<li>server：动作——process，send</li>
<li>message：怎么传输——Transport模块和方法</li>
</ol>


<p>一个简单的RPC模型：
假设有echoNum一个过程，其函数形态是：
int echoNum(int num);
从上面可以知道client要发起echoNum过程调用的时候，只需给server端传输一个整形参数即可。而server端接到这个num，直接原数返回。
开始第一次调用：
echoNum(1)
我们分析我们从客户端的角度看，会产生三种结果：1.接收到了1；2.接收到了数据，但是数字不是想要的1；3.没接收到1；</p>

<p>我们再分析下有那些原因会导致这些结果（状态）：</p>

<ul>
<li>第一种情况：server接收到client请求正常，并且处理正常在一个合理的时间返回了结果。</li>
<li>第二种情况：数据发生了错误，也许client发送数据就发送错误，或许在传输过程种出错了，又或者server process过程种就错了。总之这个问题可能在图中1～4步骤都都可能。</li>
<li>第三种情况：client等了“很久”，但是数据就没有来，他也不知道哪里出问题了，所它决定不在等了，返回值设置成失败。</li>
</ul>


<p>从上面看第一种和第三种的一个关键点就在于接收到返回隐含着等待时间的问题，加入client迟迟等不到返回该采用怎样的策略。是一直等着（block），还是我先离开过段时间我再回来（sleep），还是直接永远的离去（exit）？
再复杂化一点模型，上面只牵涉到一个请求，我们现在加入多个请求：
echoNum(1)，echoNum(2)，echoNum(3)
这下我们再分析下client的返回状态有：</p>

<ul>
<li>1,2,3</li>
<li>1,3,2</li>
<li>2,1,3</li>
<li>2,3,1</li>
<li>3,1,2</li>
<li>3,2,1</li>
</ul>


<p>调用全部有返回，只是返回的时间是不确定的，所以接收到的数据也是不确定的</p>

<ul>
<li>1,2</li>
<li>1,3</li>
<li>2,1</li>
<li>2,3</li>
<li>3,1</li>
<li>3,2</li>
<li>1</li>
<li>2</li>
<li>3</li>
<li>啥也没有接收到</li>
</ul>


<p>发生了数据丢失，上面描述了丢失一个到全部丢失的全部情况。
根据实际业务需求，上面的一些结果肯定是要被剔除的，这也是RPC的调用设计种的同步和异步问题。</p>

<p>仔细学习什么<a href="http://www.cs.cf.ac.uk/Dave/C/node33.html">RPC</a></p>

<ul>
<li>RPC的基本模型和解决的问题</li>
<li>RPC框架需要注意的问题</li>
<li>RPC框架的天生缺陷和优点</li>
<li>RPC框架的使用场景和局限性</li>
<li>和RPC对应的还有那些解决框架？各自的有缺点和应用的普遍情况</li>
</ul>


<h2>thrift的定义中的特性</h2>

<p>thrift的官方定义如下：</p>

<blockquote><p>The Apache Thrift software framework, for scalable cross-language services development, combines a software stack with a code generation engine to build services that work efficiently and seamlessly between C++, Java, Python, PHP, Ruby, Erlang, Perl, Haskell, C#, Cocoa, JavaScript, Node.js, Smalltalk, OCaml and Delphi and other languages.</p></blockquote>

<p>先解释下这个定义都讲了什么。</p>

<ul>
<li>software framework：本身是一个软件框架，只提供基础的远程通信框架，意味这你自己需要补充其中的业务逻辑</li>
<li>services development：这个框架是为了辅助开发者开发出自己的一个网络服务c/s软件，而这个服务具备接下来的两个重要特点：

<ul>
<li><a href="http://www.infoq.com/cn/news/2007/10/whatisscalability">scalable 可伸缩性</a>：？？为啥说是可伸缩的？根据可伸缩的核心特征——处理能力能随这个扩展服务规模而提升。</li>
<li>cross-language 跨语言：这个可能是thrift的最大特点了，为了实现这个特性，thrift直接为此定义了一套中间语言，并且配备了一个此语言到各种目标语言的编译器。不过说起来跨语言到底指什么呢？其实一句话概括就是服务短和客户端可以是不同语言开发的，比如官方的例子：客户端是python，服务端是java。而这个中间语言就是只定义一遍服务的逻辑语义一次，通过编译器转成各种目标语言多次。从而解决重复编写的问题。</li>
</ul>
</li>
</ul>


<h2>需要的知识背景</h2>

<p>thrift的所有技能都在操作系统和计算机网络里可以找到,
推荐书籍：</p>

<ul>
<li>计算机网络</li>
<li>Unix网络编程</li>
<li>Unix系统内幕</li>
</ul>


<h2>一个简单的开发例子</h2>

<p>thrift包括其他的RPC应用的开发步骤分为下面三个步骤:</p>

<ul>
<li>定义client和server之间通信协议（protocol），即输入输出约定方式
以为一个RPC可以通过普通的函数来描述，所以协议中也必须指出函数名称，参数类型还有返回值类型。thrift根据定义好的协议来自动生成整个RPC框架，主要封装了整套的网络传输部分，剩下的部分只是业务逻辑需要开发者自己编写。控制主了远程访问的复杂度，非常棒的设计思路。</li>
<li>开发client端程序</li>
<li>开发server端程序</li>
</ul>


<h3></h3>

<h2>通信层次</h2>

<p>因为thrift更根据定义好的thrift接口，自动生成相关结构的通信层次的代码，这可算是给程序员提供了很大的便利，不过有利也有弊，你不了解，也意味着你没办法改变。
所以当出问题了，你还是需要进行深入。</p>

<h2>Reference</h2>

<ul>
<li><a href="http://blog.csdn.net/docong/article/details/6028428">thrift 白皮书</a></li>
<li><a href="https://thrift.apache.org/static/files/thrift-20070401.pdf">thrift white paper</a></li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/01/17/business-dataming-ecosystem-investigation/">Pentaho和Pivotal</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-01-17T13:55:01+08:00'><span class='date'><span class='date-month'>Jan</span> <span class='date-day'>17</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>1:55 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>接触到的关于数据处理的商业软件基本都处于pentoha和pivotal，或者总是和这两家公司有关系，所以想做个调查，报告如下：</p>

<h1><a href="http://www.pentaho.com/">Pentaho</a></h1>

<h1><a href="https://pivotal.io/">pivotal</a></h1>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/01/13/read-note-how-google-works/">Read-note: How Google Works</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-01-13T23:39:15+08:00'><span class='date'><span class='date-month'>Jan</span> <span class='date-day'>13</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>11:39 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>创意精英：
- 过硬的专业知识，懂得如何使用专业工具，还需要具备充足的实践经验
- 拥有分析头脑，可以利用数据做出决策，同时也懂得数据的误导性，从而不会沉迷其中
- 有商业头脑，知道专业技术、优质产品和商业成功是环环相扣的、也对这三个要素的价值了然于胸
- 有创造力
- 有竞争头脑，干劲十足，即使在工作之余也不停止前进的脚步
- 用户头脑，无论身处哪里行业，几乎没有人能比他们更懂得用户或消费者对产品的看法
- 自动自发，不会坐等别人为他们指出方向，对于有悖于他们信念的知识，他们会选择充耳不闻
- 心态开放，于他们自由合作，在评判构思和结论时，看重优点和而和价值而非出处</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/posts/4">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/posts/2">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2016/09/14/learning-how-to-learn/">Learning How to Learn</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/09/04/data-file-organization/">Data File Organization</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/08/31/introduce-hive/">Introduce Hive</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/08/22/design-pattern/">Design Pattern</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/08/14/how-to-manipulate-binary-stream/">How to Manipulate Binary Stream</a>
      </li>
    
  </ul>
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2016 - Wood Carver -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  











</body>
</html>
