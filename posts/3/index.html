
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Wood Carver</title>
  <meta name="author" content="Wood Carver">

  
  <meta name="description" content="各种储存设备的速度量级 时间单位是cpu cycles。
| 储存类型 | 缓存的内容 | 储存的媒介| 处理速度| 被谁管理
|&mdash;&mdash;&mdash;&mdash;-|&mdash;&mdash;&mdash;&mdash;|&mdash;&mdash;&mdash;& &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://woodcarver.github.io/posts/3/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Wood Carver" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/libs/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<!-- link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css"-->
<!-- link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css"-->

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Wood Carver</a></h1>
  
    <h2>Find another pool</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="sitesearch" value="woodcarver.github.io">
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/book-links">Books</a></li>
  <li><a href="/about">About Me</a></li>
  <li><a href="/start-here">Start Here</a></li>
  <li><a href="/others-blog">Reading</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/05/14/important-number-in-software-system-designing/">操作系统中的各种尝试参数</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-05-14T17:48:06+08:00'><span class='date'><span class='date-month'>May</span> <span class='date-day'>14</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>5:48 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>各种储存设备的速度量级</h1>

<p>时间单位是cpu cycles。
| 储存类型    | 缓存的内容 | 储存的媒介| 处理速度| 被谁管理
|&mdash;&mdash;&mdash;&mdash;-|&mdash;&mdash;&mdash;&mdash;|&mdash;&mdash;&mdash;&ndash;|&mdash;&mdash;&mdash;|&mdash;&mdash;&mdash;
|cpu register| 4~8 byte word | 寄存器| 0| 编译器
|TLB | Address translations| On-chip TLB| 0| Hardware MMU
|L1 cache | 64-byte block| On-chip L1 cache| 1| Hardware
|L2 cache | 64-byte block| On-chip L2 cache| 10| Hardware
|L3 cache | 64-byte block| On-chip L3 cache| 30| Hardware
|Virtual memory| 4-KB page| main memory| 100| Hardware + OS
|Buffer cache| Parts of files| main memory| 100| OS
|Disk cache| Disk sectors| Disk controller| 100,00| Controller firmware
|Network cache| Parts of files| Local disk| 10,000,000| AFS/NFS client
|Browser cache| Web pages| Local disk| 10,000,000| Web browser
|Web cache    | Web pages| Remote server disks| 1,000,000,000| Web proxy server</p>

<p>从上面看到，内存的访问速度是磁盘的1万倍（不过也要看是什么磁盘，比如固态磁盘访问速度是）
固态磁盘(ssd)的读写速度：
读            |写
&mdash;&mdash;&mdash;&mdash;&ndash;|&mdash;-
顺序：250MB/s |顺序：170MB/s
随机：140MB/s |顺序：14MB/s
固态磁盘(ssd)的读写速度大概是普通磁盘的10倍。</p>

<h1>reference</h1>

<ul>
<li><a href="http://www.directionsmag.com/entry/ram-is-100-thousand-times-faster-than-disk-for-database-access/123964">ram-is-100-thousand-times-faster disk</a></li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/04/28/algorithms-summary/">Algorithms Summary</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-04-28T10:53:35+08:00'><span class='date'><span class='date-month'>Apr</span> <span class='date-day'>28</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>10:53 am</span></time>
        
      </p>
    
  </header>


  <div class="entry-content">
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/04/24/introduce-mapreduce/">Introduce MapReduce</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-04-24T19:16:20+08:00'><span class='date'><span class='date-month'>Apr</span> <span class='date-day'>24</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>7:16 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>mapreduce 的各个阶段解释</h1>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/04/23/how-to-manage-your-work/">How to Manage Your Work</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-04-23T12:06:20+08:00'><span class='date'><span class='date-month'>Apr</span> <span class='date-day'>23</span><span class='date-suffix'>rd</span>, <span class='date-year'>2016</span></span> <span class='time'>12:06 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>如何管理自己的项目</h1>

<p>不管你是Leader or not，都会牵涉到管理自己的项目问题，只是角色不一样而已。我模仿下《布道之道》的结构总结一些模式，然后在分析怎么用这些模式（或者是原则）。如何又快又好的最大化自己的工作成效呢？It&rsquo;s a question.</p>

<h2>关键点</h2>

<ol>
<li>项目跟踪</li>
<li>实时有效反馈</li>
<li>项目预判和重要级划分，时效性估计，特别是针对所谓的紧急任务</li>
<li>树立合作处理模式和规则，让合作的人可以预测</li>
<li>项目总结</li>
</ol>


<h1>如何处理一个紧急事务</h1>

<h2>事中处理</h2>

<p>可能作为一线员工，接到紧急任务的最常用方法就是，放下手中的工作然后转向紧急任务处理，因为选择安排任务的空间比较小。
而我们都知道插入任务，必定会导致已有的任务延迟或者将来规划的任务延期。而延期的多长时间就要依赖于处理插入事务的速度了。而唯一能加快处理速度的方法就是以前积累类似case的处理经验。
所以就要用到P5，一定要注意总结。</p>

<h2>事前预防</h2>

<p>这个地方可以采取的措施就很多了。
第一点就是要弄清楚为什么要做这个任务，如果对公司的业务做够熟悉（这个需要公司业务积累），那么很容易判断出来这个任务到底有没有意义或者有更优化的解决方案，或者根本就不用做了。
第二点是弄清楚自己能不能接，如果不能接（比如自己有更重要的事情要完成），建议交给别人或者让拒绝对方的无理要求。
第三点是树立自己的处理事务模式(P4)，让需求方提出需求前有个预测他们的任务会不会被自己拒绝。
第四点就是分析经历过的项目(P5)，找出模式，做好事先准备。
第五点，如果公司有很好的反馈机制，知道其他和自己相关的项目正在进行，但是还没有进行到自己这里，这里就需要使用P1，预判什么时候到自己这里，可以做事前准备。再着前置任务延迟，提醒他们延迟的后果，再一定程度上提醒前置任务的速度。</p>

<h2>事后总结</h2>

<p>任务完了，还有很多事要做，才能保证将来的工作成效能提升：
第一点：还是P5， 这里有业务方向和技术方向两大块。业务方向出来事情的意义还有事情产生的时间模式。</p>

<h1>如何判断一个项目，你能不能接</h1>

<p>当一下子来一个大项目，其实一下子估计自己什么时候完成是一个很大的挑战。
所以采取的方案就是，项目拆分。只有当项目足够小，才能被看清、预估，才能被很好的执行 —— 分冶的思想。</p>

<h1>reference</h1>

<ul>
<li><a href="https://www.livecoding.tv/udm/videos/xYvyp-1dv600-l03-planning-and-managing-projects">planning and managing pojects</a></li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/04/10/how-to-understand-a-message-sysetm/">Message System</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-04-10T18:31:31+08:00'><span class='date'><span class='date-month'>Apr</span> <span class='date-day'>10</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>6:31 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>接触了一些message system的系统（大部分是kafka），对message queue的作用和关键点有了一些了解。这些就谈谈我的认识，和使用注意事项。</p>

<h1>message queue的作用</h1>

<p>查阅了材料发现总结下来，列举的理由有十几条之多，但是直接貌似没有任何联系和组织方式。很是不好理解。我在这里使用模型的变化来阐述我自己的理解：
<img src="./images/posts/message_system.png" alt="naive" />
从上面的演化图来看，有了消息队列后的一个本质变化就是把收消息和接消息的任务都扔给了第三方，其实这就是软件行业中最一般的做法如果要获得软件的灵活性和扩展性，那么就开始加中间层。计算机网络是这么做的，同样操作系统也是这么做的。
而考虑具体的好处这个问题和系统会出现什么问题是手心手背的关系。我们就来一块一块的说。
我们假设我们要做一个买票系统。数据库使用mysql，前面只有一个售票程序来操作数据。这时候的模型就是第一个模块的样子。初期的时候一切都很完美，这个网站只拥有1万用户，每天只卖500张票。
后来发现有些背后的mysql总是宕机，导致用户订票总是不成功，所以就想着怎么把用户的订单信息先存下来，然后等mysql恢复后马上继续处理。这时候你就开始想着建立一个消息缓存队列，然后程序自然形成了一个生产者消费者模型。同时你还会发现这个不仅仅有消息缓存的好处，还有发现消息现在是可以被保存了（或者说很便捷和自然的保存了）。以前那些因为程序bug处理失败的消息可以被重复处理了。还有就是哪天突然要在mysql之上加上一层redis，那其实也不必修改上游程序。总结下来：
1. 缓冲 &ndash; 消息的缓存，当下游处于宕机状态，消息可以被缓存等待重启后继续处理。
2. 解耦 &ndash; 项目之间解耦，形成各种微服务
3. 冗余
4. 送达保证
5. 顺序保证能实现了</p>

<p>再后来你的系统的用户增加到了100万，而且因为是买的火车票，所以一到过节订单就出现高峰，这时候辛亏你有了消息队列可以帮你缓存。
6. 消除峰值 &ndash; 即消息均衡，当消息的生产速度差距很大的时候，消息可以被缓存，然后转发其他空闲的服务上或者等待等后续措施。</p>

<p>后来再发现一个消息队列因为不够存储高峰期间储蓄的数据了，这时候再增加下游的消费者处理能力很浪费，因为平时你用不着。这时候发现增加一个消息队列服务的成本去很低，那么开始扩展这里。
7. 扩展性</p>

<p>其他feature：
1. 异步通信
这个是好是坏，全看实际的引用场景。对于实时要求性很高，但是不要求消息全部保证被处理就是无所谓的特性。</p>

<ol>
<li>附赠的feature(只是更方便吧)
因为消息缓存的独立，可以对其处理速度监控，从而得知系统的负载能力。</li>
</ol>


<p>从另一个角度再看看消息队列的作用：
因为从生产者、消费者两方关系衍生到生产者、消息队列、消费者三方之间的关系，所以我们就从3个主题的角度讨论。
1. 主体一生产者会发生些什么情况：</p>

<ul>
<li>性能——流量突然增大，或者流量是不均匀的</li>
<li>部分失效——突然部分生产者挂了。如果没有消息队列，那就意味着部分消费者没有任务消费了，或者消费者自己做了任务自动均衡，这是一件比较麻烦的额事情。</li>
<li>容错性——都挂了。如果没有消息队列，那么消费者也立即进入休息状态。但是有了消息对立后以前生产的东西还能储存下来，提供消费者消费，然后有个缓冲时间窗口重启</li>
<li>扩展性——突然要增加生产者的数量，没有消息队列的情况下，意味着需要有一套re-balance的机制在里面，同样时间麻烦的事情。统统都交给消息队列考虑吧。其实这条和部分失效是一样的，都是scaling过程。</li>
<li><p>复用（解耦）——生产的消息万一不仅仅只有一个消费者，这样还需要一套分发机制。也是件麻烦的事情。有了消息队列，其实消费者和我再也没啥关系了。我爱怎么生成就怎么生产。</p></li>
<li><p>主体二消费者会发生些什么情况：</p></li>
<li><p>性能——处理速度万一跟不上呢？</p></li>
<li>扩展性——同上，消息队列提供了扩展收缩自动均衡的策略。</li>
</ul>


<h1>如果学习一个message queue？</h1>

<h2>消息可达性保证机制</h2>

<p>这个机制或者约定更确切些，就是描述系统到底怎么client进行交互，确保信息是正确的到达了目的地。一般的消息保证机制有：
1. 至多一次，保证绝对不重复发，但是有丢数据情况。这种情况server处理是最简单的，发完了就不管了，不需要和client交互。</p>

<blockquote><p>at-most-once delivery means that for each message handed to the mechanism, that message is delivered zero or one times; in more casual terms it means that messages may be lost.
2. 至少一次，保证一定client接收到了信息，如果不能确定client接收到了信息会重复发。做到这点server只要一直发知道接收到了client的ack。
at-least-once delivery means that for each message handed to the mechanism potentially multiple attempts are made at delivering it, such that at least one succeeds; again, in more casual terms this means that messages may be duplicated but not lost.
3. 精确的一次，保证不重复发但也不丢数据。exactly-once是最难保证的，因为这涉及到通信中的很多情况。
exactly-once delivery means that for each message handed to the mechanism exactly one delivery is made to the recipient; the message can neither be lost nor duplicated.</p>

<p>The first one is the cheapest—highest performance, least implementation overhead—because it can be done in a fire-and-forget fashion without keeping state at the sending end or in the transport mechanism. The second one requires retries to counter transport losses, which means keeping state at the sending end and having an acknowledgement mechanism at the receiving end. The third is most expensive—and has consequently worst performance—because in addition to the second it requires state to be kept at the receiving end in order to filter out duplicate deliveries.</p></blockquote>

<h3>为什么保证不了消息发送？</h3>

<ol>
<li>The message is sent out on the network?</li>
<li>The message is received by the other host?</li>
<li>The message is put into the target actor&rsquo;s mailbox?</li>
<li>The message is starting to be processed by the target actor?</li>
<li>The message is processed successfully by the target actor?</li>
</ol>


<p>其实就从消息传递从出发到结果的整个过程，状体包括出发、路上、进门、喝茶、出门和回家通报。
其中在路上需要花多少时间谁都不知道，还有没有万一进门后被真“喝茶”后，不返回通报的你让发送者的家人怎么办？</p>

<h2>消息顺序保证机制</h2>

<ol>
<li>保证消息一定是顺序到达的，这个地方需要考虑如果是一个kafka的系统，同一个group下的不同consumer之间的顺序怎么保证？</li>
<li>不保证消息一定顺序到达</li>
</ol>


<h1>reference</h1>

<ol>
<li><a href="http://doc.akka.io/docs/akka/2.4.3/general/message-delivery-reliability.html">Message Delivery Reliability</a></li>
<li><a href="http://www.jasongj.com/2015/01/02/Kafka%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90/">Kafka深度解析</a></li>
</ol>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/03/25/a-bug-tracing/">A Bug Tracing</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-03-25T15:36:20+08:00'><span class='date'><span class='date-month'>Mar</span> <span class='date-day'>25</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>3:36 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content">
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/03/16/study-tree/">Study Tree</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-03-16T15:00:42+08:00'><span class='date'><span class='date-month'>Mar</span> <span class='date-day'>16</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>3:00 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>Java learning</h1>

<ol>
<li><p>基本语法
这包括static、final、transient等关键字的作用，foreach循环的原理，volatile等等。今天面试我问你static关键字有哪些作用，如果你答出static修饰变量、修饰方法我会认为你合格，答出静态块，我会认为你不错，答出静态内部类我会认为你很好，答出静态导包我会对你很满意，因为能看出你非常热衷研究技术。</p></li>
<li><p>数据结构（容器）
ArrayList、LinkedList、Hashtable、HashMap、ConcurrentHashMap、HashSet的实现原理,掌握CopyOnWrite容器和Queue, 特别是ConcuurentHashMap：
（1）ConcurrentHashMap的锁分段技术
（2）ConcurrentHashMap的读是否要加锁，为什么
（3）ConcurrentHashMap的迭代器是强一致性的迭代器还是弱一致性的迭代器</p></li>
<li><p>设计模式
（1）你的项目中用到了哪些设计模式，如何使用
（2）知道常用设计模式的优缺点
（3）能画出常用设计模式的UML图</p></li>
<li><p>多线程
Thread和Runnable的区别和联系、多次start一个线程会怎么样、线程有哪些状态
假如有Thread1、Thread2、Thread3、Thread4四条线程分别统计C、D、E、F四个盘的大小，所有线程都统计完毕交给Thread5线程去做汇总，应当如何实现？
另外，线程池也是比较常问的一块，常用的线程池有几种？这几种线程池之间有什么区别和联系？线程池的实现原理是怎么样的？实际一些的，会给你一些具体的场景，让你回答这种场景该使用什么样的线程池比较合适。
<a href="http://www.cnblogs.com/xrq730/p/5060921.html">40个java多线程问题总结</a></p></li>
<li><p>Jdk源码
（1）List、Map、Set实现类的源代码
（2）ReentrantLock、AQS的源代码
（3）AtomicInteger的实现原理，主要能说清楚CAS机制并且AtomicInteger是如何利用CAS</p></li>
<li><p>Java虚拟机
（1）Java虚拟机的内存布局
（2）GC算法及几种垃圾收集器
（3）类加载机制，也就是双亲委派模型
（4）Java内存模型
（5）happens-before规则
（6）volatile关键字使用规则</p></li>
</ol>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/03/15/how-is-lambda-created/">How Is Lambda Created?</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-03-15T14:16:01+08:00'><span class='date'><span class='date-month'>Mar</span> <span class='date-day'>15</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>2:16 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content">
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/02/29/introduce-kafka/">使用kafka</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-02-29T15:16:17+08:00'><span class='date'><span class='date-month'>Feb</span> <span class='date-day'>29</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>3:16 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>kafka是什么，解决了什么问题</h1>

<p>本质上kafka是一个消息订阅发布系统，当然这种系统设计的实现已经有千千万，kafka也只是其中的一个。所以要了解kafka，我们先看看什么消息订阅发布系统和这种设计是针对解决什么问题发被发明出来的。
消息发送模式一般有两种——点对点，广播，而相应的技术是队列和订阅发布。消息队列。
当然这里再提到关于一种消息队列也是数据库的观点（message queue is database too）， 所以从kafka的设计逻辑上它实际也是一个种管理数据获取和写入的系统。所以也可以从逻辑结构和储存结构两个方面来理解系统。参看<a href="./2016-07-24-how-to-understand-d-data-system">如何理解一个数据存储系统</a>。</p>

<p>而kafka的创始人则对kafka作为data pipeline中的一个real-time stream centre bus来设定，增加了分布式的特性(扩展性和容错性)，同时以低延迟高可用为一个重要设计目标。</p>

<p>还有一个特点，那就是kafka的写入和读取都是采用batch的模型。</p>

<h2>设计消息订阅发布系统的关键点在哪里？，参看<a href="./2016-04-10-message-delivery-reliability">如何理解一个消息系统</a></h2>

<h1>kafka处在hadoop生态圈的什么位置</h1>

<h1>kafka基本模型和优缺点</h1>

<ul>
<li>基于日志</li>
</ul>


<h1>如何生产消息</h1>

<p>关键词：topic, group, partition, offset
所有的消息系统在设计消息生产的时候都要考虑消息的<strong>时序性和可达性</strong>。</p>

<h2>在时序方面</h2>

<p>kafka在这方面保证在partition内是写入顺序。其中新接口给出了partition的指派自定义规则，一种是自己定义（Partitioner接口），另一种是通过其定义了一个消息体类ProducerRecord，是一个key-value格式，就是为了保证同样的key会被放入同样的parition上（注意这可能导致数据倾斜）。如果key被设置为null，那么parition指派规则就使用 default partitioner 规则—— Round-robin，随机分配。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;String, String&gt;("Country", "Precision Products", "France");</span></code></pre></td></tr></table></div></figure>


<p>至于当摸个partition突然失效，那么相应的key的message会怎么办？这个就是设计到了kafka的容错机制——replication and availability.</p>

<h2>可达性而言</h2>

<p>所有的可达性都需要客户端的配合才能形式要求的特性（at -most-once, at-least-once and exactly-once）。</p>

<p>现在有个大大的问题 —— 消息到底写没写成功？假如现在对消息的写入成功要求非常高，一定需要这件事情。所以客户端需要有个信号告诉这件事情，所以如果kafka告诉客户端写成功了，客户端就认为写成功了，然后进行下一条消息操作。</p>

<p>大多数人想想的都是这样的：</p>

<p><img src="https://img3.doubanio.com/view/photo/photo/public/p2375588550.jpg" alt="normal" />
这是最理想的情况，最麻烦就是出现异常情况，我们首先来列下那些异常会出现：</p>

<p>至少涉及到消息都会有两种状态，到达了和超时。</p>

<table>
<thead>
<tr>
<th> 情况  </th>
<th> 消息发送</th>
<th> 确认（ack）发送</th>
</tr>
</thead>
<tbody>
<tr>
<td>接收到反馈，反馈是成功</td>
<td>完事了</td>
<td> 完事</td>
</tr>
<tr>
<td>接收到反馈，反馈是失败</td>
<td>重写  </td>
<td> 重写</td>
</tr>
<tr>
<td>超时</td>
<td>？</td>
<td>？</td>
</tr>
</tbody>
</table>


<p>假如接收到反馈，反馈是失败，那么也很简单，那就是再重写一遍。
但是最复杂的情况就是ack超时的情况，以为超时可能有下面几种可能造成的：
<img src="https://img3.doubanio.com/view/photo/photo/public/p2375588551.jpg" alt="message loss" />
如果是信息丢失了，我可以重写如一遍嘛，好解决。但是如果是ack丢失了，按照上面添加的规则，<strong>信息重复了</strong>！重点还是这两种情况对于客户端来说是没办法区分的。这可以容忍就要看具体业务了？</p>

<p>从kafka的API看出，其消息是通过异步的Future类实现。要怎么处理消息的可达性的自主权其实完全交给了用户自己决定。包括storm也是这么做的。</p>

<p><img src="https://img3.doubanio.com/view/photo/photo/public/p2375588553.jpg" alt="message loss" /></p>

<p>具体实现方式通过kafka的Producer的配置：</p>

<ol>
<li><p>acks：描述接收broker的确认信息的机制。这个是一个int型，其数量描述的是有多少replica响应的acks（和replica的leader模型有关系）。当值为0的时候，表示不接受确认直接返回，也就是说不确认信息是否怎的写入了broker。意味着at-most-once模型。当然这种也是发送吞吐量最高的模型。
当acks=1时候，接收leader的acks响应。当然这种也有丢失数据的风险，当leader crash了或者当新leader被选中但是却没有这个消息的副本。
当acks = all，接收所有replica的确认信息。</p></li>
<li><p>retries：描述producer发送失败的时候，重试的次数。</p></li>
</ol>


<h1>如何消费消息</h1>

<p>关键词：topic, group, partition, offset</p>

<p>同样所有的消息系统在设计消息消费的时候都要考虑消息的<strong>时序性和可达性</strong>。而kafka的时序性则表现在<strong>partition内保持有序的，partition之间无序</strong>，这样也就是意味着一个partition在一个group只能被一个consumer消费。而不会出现一个partition对应多个consumer的现象。这个特性配合上producer可以指定写入partition的规则，能做很多序列化的事情。下面的图展示的是partition的数量和consumer数量各种情况下的模型：</p>

<h2>时序性</h2>

<ol>
<li><p>partition数量大于consumer数量：
<img src="https://img3.doubanio.com/view/photo/photo/public/p2375588545.jpg" alt="naive" /></p></li>
<li><p>partition数量等于consumer数量：
<img src="https://img1.doubanio.com/view/photo/photo/public/p2375588547.jpg" alt="naive" /></p></li>
<li><p>partition数量小于consumer数量：
<img src="https://img1.doubanio.com/view/photo/photo/public/p2375588548.jpg" alt="naive" />
看见有consumer开始轮空了。这个就是为了保证一个partition内的时序性。所以在扩展的时候需要保证partition数量大于consumer数量的，否则有些consumer就浪费了。</p></li>
</ol>


<h2>讲完时序性，现在开始讲可达性。</h2>

<p>kafka的消息可达性保证是通过committed offset这个机制实现的。什么是committed offset呢？</p>

<blockquote><p>We call the action of updating the current position in the partition a commit.</p></blockquote>

<p> 那就是在一个共享的地方更新每个partition的处理位置。即读的过程中告诉某个人（其实是通过__consumer_offsets这个特殊的topic实现的？怎么实现的？）我读到哪里了。但是这里有个问题就是回报和实现处理的步调可能不一致，然后到底怎么选择就看实际业务需求了。kafka提供了自动commit机制——定时回报offset，明显是异步。同时又提供了同步和异步commit的接口供使用。</p>

<ol>
<li>使用auto commit</li>
<li>使用同步commit</li>
<li>使用异步commit</li>
</ol>


<p>既然partition和consumer数量都是不限制的，那就会涉及到系统设计的核心问题——rescale(rebalance)。</p>

<h1>How to scale kafka?</h1>

<p>我们都知道在分布式储存系统是为了能够并行，必须做两件事情，一个是partition or sharding， 另一个是replica。当然kafka都做了，并且还提供了partition的显示调度接口。所以这个小节来看看kafka是怎么做parition的。</p>

<h1>消息本身 ——  消息的格式</h1>

<p>kafa的消息格式是规定好的二进制协议的，这点和redis的策略一样。所以客户端只要传输二进制流给服务端即可。因为这和语言无关，所以客户端可以采用任何一种语言，而不仅仅限于java。</p>

<blockquote><p>Kafka has a binary wire protocol. This means that it is possible for applications to read messages from Kafka or write messages to Kafka simply by sending the cor‐ rect byte sequences to Kafka’s network port. There are multiple cli‐ ents that implement Kafka’s wire protocol in different programming language, giving simple ways to use Kafka not just in Java applications but also in languages like C++, Python, Go and many more. Those clients are not part of Apache Kafka project, but a list of those is maintained in the project wiki 1. The wire protocol and the external clients are outside the scope of the chapter.</p></blockquote>

<h1>Replica设计</h1>

<p>kafka的replica的单元是partition而不是topic，而每个partition有一个leader和0到多个的followers。</p>

<p>As with most distributed systems automatically handling failures requires having a precise definition of what it means for a node to be &ldquo;alive&rdquo;. For Kafka node liveness has two conditions</p>

<ol>
<li>A node must be able to maintain its session with ZooKeeper (via ZooKeeper&rsquo;s heartbeat mechanism)</li>
<li>If it is a slave it must replicate the writes happening on the leader and not fall &ldquo;too far&rdquo; behind</li>
</ol>


<p>Kafka will remain available in the presence of node failures after a short fail-over period, but may not remain available in the presence of network partitions.</p>

<h1>设计巧妙的地方？</h1>

<ul>
<li><p>partition的设计非常巧妙</p>

<ol>
<li>和key绑定，相当于Bigtable中的raw key ，可以自由选择如何sharding数据。</li>
<li>partition内的时序性保证，解决了一些不能乱序的消息</li>
<li>rebalance（committed offset管理）, 当parition增加和减少的时候，如果rebalance consumer，当然如何rebalance producer（can？）？</li>
</ol>
</li>
<li><p>group的设计</p>

<ol>
<li>能够轻松的并行，并随意的扩展</li>
</ol>
</li>
<li><p>offset管理</p>

<ol>
<li>committed offset</li>
</ol>
</li>
<li><p>batch模式</p>

<ol>
<li>当然是为了加速</li>
</ol>
</li>
</ul>


<h1>reference</h1>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/02/22/notes-for-hadoop-the-defintive-guid/">Hadoop权威指南笔记</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-02-22T15:13:26+08:00'><span class='date'><span class='date-month'>Feb</span> <span class='date-day'>22</span><span class='date-suffix'>nd</span>, <span class='date-year'>2016</span></span> <span class='time'>3:13 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>阅读 <a href="http://blog.nosqlfan.com/html/744.html">MapReduce: A major step backwards</a></h1>

<p>这个是2014年图灵奖获得者Michael Stonebraker和David J. DeWitt。两位都是数据库界的领军人物。
下面主要介绍下文章对mapreduce提出的质疑和观点</p>

<h2>mapreduce的理念设计方面</h2>

<ul>
<li>在数据库Schema(结构和数据的关系)方面，破坏了40年的数据实践条律：

<ul>
<li>Schemas是有益的——没有schema的存在，数据可以被任意填充，所以会有很多的垃圾数据出现</li>
<li>将schema和程序分开处理是有益的——指mapreduce把数据结构都埋藏在代码中，非常不便与重复提出和维护</li>
<li>High-level存取语言是有益的——关系型数据库使用一种声明式存取方法，而不展现出存取的具体算法。而mapreduce直接把整个存取算法过程仍给使用者
这里主要是说mapreduce中的两个步骤都和应用紧密结合，可以填充任意操作</li>
</ul>
</li>
</ul>


<h2>mapreduce的实现方面</h2>

<ul>
<li>没有索引，所以所有搜索都是暴力的顺序搜索。</li>
<li>mapreduce的并行特性，早在19世界80年代就有成熟的商业产品，例如Teradata，Gamma等，和这些软件比起来mapreduce并没有特别突出的地方。</li>
<li>mapreduce的map阶段有数据倾斜的分线（skew，类似于一个二叉树中的非平衡情况，如果特别不平衡直接会使搜索退化成了顺序的）会直接降低并行的计算能力</li>
<li>mapreduce中的reduce获取map的结果方式使用的是pull（map的结果一般存放在map的本地机器上）,这是一个巨大的性能瓶颈。原文提出使用push paradigm代替pull paradigm，这个具体不太明白？</li>
</ul>


<h2>mapreduce概念一点都不新鲜</h2>

<h2>mapreduce缺乏现有数据库的关键特性,对终端使用者造成了很大困扰</h2>

<ul>
<li>Bulk loader — to transform input data in files into a desired format and load it into a DBMS</li>
<li>Indexing — as noted above</li>
<li>Updates — to change the data in the data base</li>
<li>Transactions — to support parallel update and recovery from failures during update</li>
<li>Integrity constraints — to help keep garbage out of the data base</li>
<li>Referential integrity — again, to help keep garbage out of the data base</li>
<li>Views — so the schema can change without having to rewrite the application program</li>
</ul>


<h2>mapreduce不兼容现有的DBMS工具</h2>

<ul>
<li>Report writers (e.g., Crystal reports) to prepare reports for human visualization</li>
<li>Business intelligence tools (e.g., Business Objects or Cognos) to enable ad-hoc querying of large data warehouses</li>
<li>Data mining tools (e.g., Oracle Data Mining or IBM DB2 Intelligent Miner) to allow a user to discover structure in large data sets</li>
<li>Replication tools (e.g., Golden Gate) to allow a user to replicate data from on DBMS to another</li>
<li>Database design tools (e.g., Embarcadero) to assist the user in constructing a data base.</li>
</ul>


<p>文章最后呼吁mapreduce的开发这了解最近25年内并行数据库文献，放下自以为是的态度，汲取40年的数据库发展经历和各方观点解决上面提出的问题。</p>

<p>这篇文章写的年代比较早，现在已经有了很多基于mapreduce的工具。比如hive，实现了很多现代数据库的很多特性。比如，物理数据结构和logical schame分离；提供方便的查询语言（一种类似SQL语言）；提供了Bulk loader工具。
当然hive只是在hadoop上建设了一层中间转层，提供了数据的逻辑结构，但是仍然不提供修改数据等功能等。这个和mysql等现有的关系性数据库从数据入库开始就做强约束的策略是不一样的。所以hive在写入文件是没有强约束的，而约束是只发生在读取数据时候。</p>

<h1>阅读 <a href="http://scienceblogs.com/goodmath/2008/01/22/databases-are-hammers-mapreduc/">Databases are hammers; MapReduce is a screwdriver</a></h1>

<p>文章上来就指出关系数据库的拥护者过于痴迷于这种完美的工具，以至于本末倒置的宁愿把螺丝当钉子使用，就因为有这么完美的锤子（指关系型数据库）在手。
接下来开始列车作者的观点：
- 关系型数据库不能很好并行运行
- 不能很好的处理非结构化数据
- 在处理内嵌结构数据上也背负恶名
<strong> MapReduce的目的不是用来取代Relation Ddatabase，而是祢补其缺点的，提供一种轻量级并行编程，解决另外一族计算问题。 </strong></p>

<p>这篇文章是回应上面那篇文章的，并一一针对上面的各种观点提出了自己的看法。
- 没有索引，所以所有搜索都是暴力的顺序搜索 —— 回应是：大多数大规模数据计算是使用不了关系数据模型在单机上进行的，且索引这种中心式结构很容易成为性能瓶颈，还有当计算是密集型的时候，索引是没有用的
- mapreduce缺乏现有数据库的关键特性 —— 回应是：难道不是关系型就是不好的吗？（两篇文章感觉火药味十足啊！）
- mapreduce不兼容现有的DBMS工具 —— 回应是：如果继续兼容现有DBMS，就想上面提到的为了使用锤子，而错把螺丝钉当钉子使用</p>

<h1>说了那么多，我们谈谈mapreduce是个什么东西</h1>

<p>mapreduce是一个分布式批量计算框架。想必听到这句话的时候大家应该和我一样会问计算框架是个什么东西，也有可能就是吓的不敢问了？
最粗的方式：
- map
- reduce</p>

<p>其次粒度，6个阶段：
- input ： 这个阶段注意输入格式
- split ：这个阶段注意split的性能
- map
- shuffle
- reduce ： 注意数据倾斜
- output ：注意输出格式</p>

<p>最细粒度：
- input
- split
- mapper
- combiner
- partitioner
到这里都是本地机器内操作
- shuffle
- reduce
- output</p>

<h2>一个mapreduce job的启动过程</h2>

<p>话说说完了计算框架的逻辑，那么要运行一个计算任务该怎么做？发现又是另一套东西，怎么都是感觉表面一套背地里一套！</p>

<h2>第一版的过程</h2>

<h2>为什么需要yarn？</h2>

<p>如果不是在大量环境中运行一段时候后，意识到了大量的问题后，估计每个人都会觉得上面的方案已经很完美了。所以这里先提出mapreduce框架的缺陷：
1. 我们都知道，只要是master结构的架构，随着需求的不断扩大瓶颈一般都会出在master身上，而JobTracker这个这个master。因为JobTracker的限制，所有的资源分配任务和监视任务都集中在Jobtracker上面。所有当集群特别大的时候，内存，cup等肯定会出现问题。
2. master结构还有一个问题，就是单点问题，加入master一挂，那么整个系统就挂了，这和分布式系统倡导高可用、容错特性背向而驰。而当集群越来越大，job越来愈多，都靠Jobtracker调度，那么其挂的可能性有增大的很多。
3. 不完美的不仅是Jobtracker，还有TaskTracker。问题就在于TaskTracker把资源强制划分为 map task slot 和 reduce task slot, 如果当系统中只有 map task 或者只有 reduce task 的时候，会造成资源的浪费，也就是前面提过的集群资源利用的问题。这样就会经常出现一个job的map任务都做完了，但是reduce阶段却获得不了资源而终止，很是浪费。
4. TaskTracker对任务的大小也没做考虑，有些任务大，有些任务小。假如两个都很占用内存的任务遇到一起，就会导致OOM，Task失败。</p>

<h2>编写mapreduce</h2>

<h3>万恶的数据倾斜</h3>

<ol>
<li>为什么会发生数据倾斜
根据上面mapreduce逻辑过程我们发现，数据倾斜不可能发生在map过程，都是发生在reduce过程。为什么呢？因为shuffle过程有个规则就是同样的key会发往同一个reduce上，所以到出现key1的记录条数是10亿，而key2的记录条数是10个，那么接到key1的reduce可就要倒霉了，同时其他的reduce也要陪着慢慢的等。</li>
</ol>


<p>怎么解决呢？（难道mapreduce自己没有解决机制吗？）</p>

<ul>
<li>既然出现大key的时候会出现倾斜，那么直接的解决方法就是把大key给拆了，可以通过加后缀的方式改变key值。</li>
</ul>


<h1>hadoop的另一大旗舰产品——HDFS</h1>

<h2>reference</h2>

<ul>
<li><a href="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-yarn/">Hadoop 新 MapReduce 框架 Yarn 详解</a></li>
</ul>

</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/posts/4">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/posts/2">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2017/02/24/data-visualization-d3js/">Data Visualization - D3js</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/11/13/ctr/">Ctr</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/11/06/computational-advertising/">Computational Advertising</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/10/24/the-power-of-infomation-and-time/">The Power of Infomation and Time</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/09/14/learning-how-to-learn/">Learning How to Learn</a>
      </li>
    
  </ul>
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2017 - Wood Carver -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  











</body>
</html>
