
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Wood Carver</title>
  <meta name="author" content="Wood Carver">

  
  <meta name="description" content="
">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://woodcarver.github.io/posts/3/">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="Wood Carver" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/libs/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="/javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<!-- link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css"-->
<!-- link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css"-->

  

</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Wood Carver</a></h1>
  
    <h2>Find another pool</h2>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="sitesearch" value="woodcarver.github.io">
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/book-links">Books</a></li>
  <li><a href="/about">About Me</a></li>
  <li><a href="/start-here">Start Here</a></li>
  <li><a href="/others-blog">Reading</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/03/25/a-bug-tracing/">A Bug Tracing</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-03-25T15:36:20+08:00'><span class='date'><span class='date-month'>Mar</span> <span class='date-day'>25</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>3:36 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content">
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/03/16/study-tree/">Study Tree</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-03-16T15:00:42+08:00'><span class='date'><span class='date-month'>Mar</span> <span class='date-day'>16</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>3:00 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>Java learning</h1>

<ol>
<li><p>基本语法
这包括static、final、transient等关键字的作用，foreach循环的原理，volatile等等。今天面试我问你static关键字有哪些作用，如果你答出static修饰变量、修饰方法我会认为你合格，答出静态块，我会认为你不错，答出静态内部类我会认为你很好，答出静态导包我会对你很满意，因为能看出你非常热衷研究技术。</p></li>
<li><p>数据结构（容器）
ArrayList、LinkedList、Hashtable、HashMap、ConcurrentHashMap、HashSet的实现原理,掌握CopyOnWrite容器和Queue, 特别是ConcuurentHashMap：
（1）ConcurrentHashMap的锁分段技术
（2）ConcurrentHashMap的读是否要加锁，为什么
（3）ConcurrentHashMap的迭代器是强一致性的迭代器还是弱一致性的迭代器</p></li>
<li><p>设计模式
（1）你的项目中用到了哪些设计模式，如何使用
（2）知道常用设计模式的优缺点
（3）能画出常用设计模式的UML图</p></li>
<li><p>多线程
Thread和Runnable的区别和联系、多次start一个线程会怎么样、线程有哪些状态
假如有Thread1、Thread2、Thread3、Thread4四条线程分别统计C、D、E、F四个盘的大小，所有线程都统计完毕交给Thread5线程去做汇总，应当如何实现？
另外，线程池也是比较常问的一块，常用的线程池有几种？这几种线程池之间有什么区别和联系？线程池的实现原理是怎么样的？实际一些的，会给你一些具体的场景，让你回答这种场景该使用什么样的线程池比较合适。
<a href="http://www.cnblogs.com/xrq730/p/5060921.html">40个java多线程问题总结</a></p></li>
<li><p>Jdk源码
（1）List、Map、Set实现类的源代码
（2）ReentrantLock、AQS的源代码
（3）AtomicInteger的实现原理，主要能说清楚CAS机制并且AtomicInteger是如何利用CAS</p></li>
<li><p>Java虚拟机
（1）Java虚拟机的内存布局
（2）GC算法及几种垃圾收集器
（3）类加载机制，也就是双亲委派模型
（4）Java内存模型
（5）happens-before规则
（6）volatile关键字使用规则</p></li>
</ol>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/03/15/how-is-lambda-created/">How Is Lambda Created?</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-03-15T14:16:01+08:00'><span class='date'><span class='date-month'>Mar</span> <span class='date-day'>15</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>2:16 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content">
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/02/29/introduce-kafka/">使用kafka</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-02-29T15:16:17+08:00'><span class='date'><span class='date-month'>Feb</span> <span class='date-day'>29</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>3:16 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>kafka是什么，解决了什么问题</h1>

<p>本质上kafka是一个消息订阅发布系统，当然这种系统设计的实现已经有千千万，kafka也只是其中的一个。所以要了解kafka，我们先看看什么消息订阅发布系统和这种设计是针对解决什么问题发被发明出来的。
消息发送模式一般有两种——点对点，广播，而相应的技术是队列和订阅发布。消息队列。
当然这里再提到关于一种消息队列也是数据库的观点（message queue is database too）， 所以从kafka的设计逻辑上它实际也是一个种管理数据获取和写入的系统。所以也可以从逻辑结构和储存结构两个方面来理解系统。参看<a href="./2016-07-24-how-to-understand-d-data-system">如何理解一个数据存储系统</a>。</p>

<p>而kafka的创始人则对kafka作为data pipeline中的一个real-time stream centre bus来设定，增加了分布式的特性(扩展性和容错性)，同时以低延迟高可用为一个重要设计目标。</p>

<p>还有一个特点，那就是kafka的写入和读取都是采用batch的模型。</p>

<h2>设计消息订阅发布系统的关键点在哪里？，参看<a href="./2016-04-10-message-delivery-reliability">如何理解一个消息系统</a></h2>

<h1>kafka处在hadoop生态圈的什么位置</h1>

<h1>kafka基本模型和优缺点</h1>

<ul>
<li>基于日志</li>
</ul>


<h1>如何生产消息</h1>

<p>关键词：topic, group, partition, offset
所有的消息系统在设计消息生产的时候都要考虑消息的<strong>时序性和可达性</strong>。
在时序方面，kafka在这方面保证在partition内是写入顺序。
对可达性而言，所有的可达性都需要客户端的配合才能形式要求的特性（at -most-once, at-least-once and exactly-once）。</p>

<p>现在有个大大的问题 —— 消息到底写没写成功？假如现在对消息的写入成功要求非常高，一定需要这件事情。所以客户端需要有个信号告诉这件事情，所以如果kafka告诉客户端写成功了，客户端就认为写成功了，然后进行下一条消息操作。</p>

<p>大多数人想想的都是这样的：</p>

<p><img src="./images/posts/kafka_producer1.png" alt="normal" />
这是最理想的情况，最麻烦就是出现异常情况，我们首先来列下那些异常会出现：</p>

<p>至少涉及到消息都会有两种状态，到达了和超时。</p>

<table>
<thead>
<tr>
<th> 情况  </th>
<th> 消息发送</th>
<th> 确认（ack）发送</th>
</tr>
</thead>
<tbody>
<tr>
<td>接收到反馈，反馈是成功</td>
<td>完事了</td>
<td> 完事</td>
</tr>
<tr>
<td>接收到反馈，反馈是失败</td>
<td>重写  </td>
<td> 重写</td>
</tr>
<tr>
<td>超时</td>
<td>？</td>
<td>？</td>
</tr>
</tbody>
</table>


<p>假如接收到反馈，反馈是失败，那么也很简单，那就是再重写一遍。
但是最复杂的情况就是ack超时的情况，以为超时可能有下面几种可能造成的：
<img src="./images/posts/kafka_producer2.png" alt="message loss" />
如果是信息丢失了，我可以重写如一遍嘛，好解决。但是如果是ack丢失了，按照上面添加的规则，<strong>信息重复了</strong>！重点还是这两种情况对于客户端来说是没办法区分的。这可以容忍吗就要看具体业务了？</p>

<p>从kafka的API看出，其消息是通过异步的Future类实现。要怎么处理消息的可达性其实完全交给了用户自己决定。包括storm也是这么做的。</p>

<p><img src="./images/posts/kafka_producer3.png" alt="message loss" /></p>

<h1>如何消费消息</h1>

<p>关键词：topic, group, partition, offset</p>

<p>同样所有的消息系统在设计消息消费的时候都要考虑消息的<strong>时序性和可达性</strong>。而kafka的时序性则表现在<strong>partition内保持有序的，partition之间无序</strong>，这样也就是意味着一个partition在一个group只能被一个consumer消费。而不会出现一个partition对应多个consumer的现象。这个特性配合上producer可以指定写入partition的规则，能做很多序列化的事情。下面的图展示的是partition的数量和consumer数量各种情况下的模型：</p>

<ol>
<li><p>partition数量大于consumer数量：
<img src="./images/posts/kafka_consumer1.png" alt="naive" /></p></li>
<li><p>partition数量等于consumer数量：
<img src="./images/posts/kafka_consumer2.png" alt="naive" /></p></li>
<li><p>partition数量小于consumer数量：
<img src="./images/posts/kafka_consumer3.png" alt="naive" />
看见有consumer开始轮空了。这个就是为了保证一个partition内的时序性。所以在扩展的时候需要保证partition数量大于consumer数量的，否则有些consumer就浪费了。</p></li>
</ol>


<p>讲完时序性，现在开始讲可达性。</p>

<p>既然partition和consumer数量都是不限制的，那就会涉及到系统设计的核心问题——rescale(rebalance)。</p>

<h1>How to scale kafka?</h1>

<p>我们都知道在分布式储存系统是为了能够并行，必须做两件事情，一个是partition or sharding， 另一个是replica。当然kafka都做了，并且还提供了partition的显示调度接口。所以这个小节来看看kafka是怎么做parition的。</p>

<h1>消息本身 ——  消息的格式</h1>

<p>kafa的消息格式是规定好的二进制协议的，这点和redis的策略一样。所以客户端只要传输二进制流给服务端即可。因为这和语言无关，所以客户端可以采用任何一种语言，而不仅仅限于java。</p>

<blockquote><p>Kafka has a binary wire protocol. This means that it is possible for applications to read messages from Kafka or write messages to Kafka simply by sending the cor‐ rect byte sequences to Kafka’s network port. There are multiple cli‐ ents that implement Kafka’s wire protocol in different programming language, giving simple ways to use Kafka not just in Java applications but also in languages like C++, Python, Go and many more. Those clients are not part of Apache Kafka project, but a list of those is maintained in the project wiki 1. The wire protocol and the external clients are outside the scope of the chapter.</p></blockquote>

<h1>reference</h1>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/02/22/notes-for-hadoop-the-defintive-guid/">Hadoop权威指南笔记</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-02-22T15:13:26+08:00'><span class='date'><span class='date-month'>Feb</span> <span class='date-day'>22</span><span class='date-suffix'>nd</span>, <span class='date-year'>2016</span></span> <span class='time'>3:13 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>阅读 <a href="http://blog.nosqlfan.com/html/744.html">MapReduce: A major step backwards</a></h1>

<p>这个是2014年图灵奖获得者Michael Stonebraker和David J. DeWitt。两位都是数据库界的领军人物。
下面主要介绍下文章对mapreduce提出的质疑和观点</p>

<h2>mapreduce的理念设计方面</h2>

<ul>
<li>在数据库Schema(结构和数据的关系)方面，破坏了40年的数据实践条律：

<ul>
<li>Schemas是有益的——没有schema的存在，数据可以被任意填充，所以会有很多的垃圾数据出现</li>
<li>将schema和程序分开处理是有益的——指mapreduce把数据结构都埋藏在代码中，非常不便与重复提出和维护</li>
<li>High-level存取语言是有益的——关系型数据库使用一种声明式存取方法，而不展现出存取的具体算法。而mapreduce直接把整个存取算法过程仍给使用者
这里主要是说mapreduce中的两个步骤都和应用紧密结合，可以填充任意操作</li>
</ul>
</li>
</ul>


<h2>mapreduce的实现方面</h2>

<ul>
<li>没有索引，所以所有搜索都是暴力的顺序搜索。</li>
<li>mapreduce的并行特性，早在19世界80年代就有成熟的商业产品，例如Teradata，Gamma等，和这些软件比起来mapreduce并没有特别突出的地方。</li>
<li>mapreduce的map阶段有数据倾斜的分线（skew，类似于一个二叉树中的非平衡情况，如果特别不平衡直接会使搜索退化成了顺序的）会直接降低并行的计算能力</li>
<li>mapreduce中的reduce获取map的结果方式使用的是pull（map的结果一般存放在map的本地机器上）,这是一个巨大的性能瓶颈。原文提出使用push paradigm代替pull paradigm，这个具体不太明白？</li>
</ul>


<h2>mapreduce概念一点都不新鲜</h2>

<h2>mapreduce缺乏现有数据库的关键特性,对终端使用者造成了很大困扰</h2>

<ul>
<li>Bulk loader — to transform input data in files into a desired format and load it into a DBMS</li>
<li>Indexing — as noted above</li>
<li>Updates — to change the data in the data base</li>
<li>Transactions — to support parallel update and recovery from failures during update</li>
<li>Integrity constraints — to help keep garbage out of the data base</li>
<li>Referential integrity — again, to help keep garbage out of the data base</li>
<li>Views — so the schema can change without having to rewrite the application program</li>
</ul>


<h2>mapreduce不兼容现有的DBMS工具</h2>

<ul>
<li>Report writers (e.g., Crystal reports) to prepare reports for human visualization</li>
<li>Business intelligence tools (e.g., Business Objects or Cognos) to enable ad-hoc querying of large data warehouses</li>
<li>Data mining tools (e.g., Oracle Data Mining or IBM DB2 Intelligent Miner) to allow a user to discover structure in large data sets</li>
<li>Replication tools (e.g., Golden Gate) to allow a user to replicate data from on DBMS to another</li>
<li>Database design tools (e.g., Embarcadero) to assist the user in constructing a data base.</li>
</ul>


<p>文章最后呼吁mapreduce的开发这了解最近25年内并行数据库文献，放下自以为是的态度，汲取40年的数据库发展经历和各方观点解决上面提出的问题。</p>

<p>这篇文章写的年代比较早，现在已经有了很多基于mapreduce的工具。比如hive，实现了很多现代数据库的很多特性。比如，物理数据结构和logical schame分离；提供方便的查询语言（一种类似SQL语言）；提供了Bulk loader工具。
当然hive只是在hadoop上建设了一层中间转层，提供了数据的逻辑结构，但是仍然不提供修改数据等功能等。这个和mysql等现有的关系性数据库从数据入库开始就做强约束的策略是不一样的。所以hive在写入文件是没有强约束的，而约束是只发生在读取数据时候。</p>

<h1>阅读 <a href="http://scienceblogs.com/goodmath/2008/01/22/databases-are-hammers-mapreduc/">Databases are hammers; MapReduce is a screwdriver</a></h1>

<p>文章上来就指出关系数据库的拥护者过于痴迷于这种完美的工具，以至于本末倒置的宁愿把螺丝当钉子使用，就因为有这么完美的锤子（指关系型数据库）在手。
接下来开始列车作者的观点：
- 关系型数据库不能很好并行运行
- 不能很好的处理非结构化数据
- 在处理内嵌结构数据上也背负恶名
<strong> MapReduce的目的不是用来取代Relation Ddatabase，而是祢补其缺点的，提供一种轻量级并行编程，解决另外一族计算问题。 </strong></p>

<p>这篇文章是回应上面那篇文章的，并一一针对上面的各种观点提出了自己的看法。
- 没有索引，所以所有搜索都是暴力的顺序搜索 —— 回应是：大多数大规模数据计算是使用不了关系数据模型在单机上进行的，且索引这种中心式结构很容易成为性能瓶颈，还有当计算是密集型的时候，索引是没有用的
- mapreduce缺乏现有数据库的关键特性 —— 回应是：难道不是关系型就是不好的吗？（两篇文章感觉火药味十足啊！）
- mapreduce不兼容现有的DBMS工具 —— 回应是：如果继续兼容现有DBMS，就想上面提到的为了使用锤子，而错把螺丝钉当钉子使用</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/02/17/deep-insight-of-linux-system-status-description-commands/">Linux系统状态命令详解</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-02-17T21:58:48+08:00'><span class='date'><span class='date-month'>Feb</span> <span class='date-day'>17</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>9:58 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>知识地图</h1>

<p>这篇文章整理的是对关于诊断linux系统状况的相关指标和命令。涉及到：
1. I/O负载状况
2. 进程控制
3. cpu负载状况
4. memory占用情况
5. disk使用情况</p>

<h1>Commands about I/O</h1>

<ul>
<li><p>什么是I/O
再让我们看一眼csapp的那幅经典图
<img src="/images/posts/computer_organization.png" alt="computer organization" />
看到所有的设备都是通过I/O bridge把数据移动到Main memory上，然后再主存再和CPU交互进行计算。当CPU有输出时，也是先输出到主存上，然后再输入到设备上。而再计算机中I/O设备就只除去CPU和主存的设备，也成外围设备。
介绍完I/O设备，那什么是I/O呢？按照《Unix系统内幕》的定义：</p>

<blockquote><p>The I/O subsystem haldes the movement of data between memory and peripheral devices such as disks, printers, and terminals.
所以I/O就是指I/O设备和memory之间数据移动。</p></blockquote></li>
<li><p>怎么才算是一次I/O</p>

<h2>iostat</h2>

<h2>top</h2>

top对I/O的描述是用I/O wait这个指标，例如下图：
<img src="/images/posts/top_command_short.png" alt="top command" />
其中I/O wait 的定义是：

<blockquote><p>I/O wait is the percentage of time your processors are waiting on the disk.
I/O wait就是CPU在整个任务处理中等待闲置的时间，举个例子：一个任务一共使用了1s，但是其中从从磁盘中取数据花了700ms，而在磁盘读取数据时CPU是闲置的，所以CPU的等待I/O的时间占了70%，即I/O wait 是70%。
当然有人指出对多核cpu通过iowait来统计io的负载情况并不准确，<a href="http://veithen.github.io/2013/11/18/iowait-linux.html">详见</a></p></blockquote></li>
</ul>


<p><code>threshold：当I/O wait &gt; 1/CPU_cores 可以判断明显出现了I/O瓶颈(why?)。</code></p>

<h2>sar</h2>

<p>同样使用I/O wait这个指标，每10mini(默认时间间隔，可以调节)纪录一次系统状态值,保留一段时间的历史数据。</p>

<h2>dstat</h2>

<p>发现这个命令组合很有意思
dstat -tdD total,sda,sdb,sdc,md1 60</p>

<h2>Reference</h2>

<ul>
<li>[深入理解计算机系统（第二版）]</li>
<li>[Unix系统内幕]</li>
<li><a href="http://blog.scoutapp.com/articles/2011/02/10/understanding-disk-i-o-when-should-you-be-worried">understanding disk i/o - when should you be worried?</a></li>
<li><a href="http://veithen.github.io/2013/11/18/iowait-linux.html">The precise meaning of I/O wait time in Linux</a></li>
</ul>


<h1>进程控制</h1>

<ul>
<li>exec</li>
<li>source</li>
<li>kill</li>
<li>bg,fg,jobs</li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/01/26/introduce-thrift/">Introduce Thrift</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-01-26T14:46:14+08:00'><span class='date'><span class='date-month'>Jan</span> <span class='date-day'>26</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>2:46 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><h2>History</h2>

<ul>
<li>诞生于facebook
facebook开源出的RPC开源框架，现在已经成为Apache的顶级项目。</li>
</ul>


<h2>Why need thrift</h2>

<p>This question can also be instead of another one&ndash;Is RPC service complicated?
Before I try to know distributed system, I don&rsquo;t know that it need using a book to make PRC clearly and RPC is an absolutly important skill requirement on service developing posistion.
If you want to know thrift, you must know RPC.</p>

<h2>What is RPC</h2>

<p>RPC的全称是Remote Procedure Call。这种类型的技术专注与格式化客户端和服务端传输，以实现更方便的远程交互，甚至能做到和本地调用无多大区别的程度。
整个过程是客户端发送RPC请求到服务端，服务端处理后再发结果反馈过来。听这很简单，看着很容易，而且很熟悉。这不就是cs模型吗？但是其中涉及的难点就隐藏在老生常谈的信息通信中。比如消息体的打包，拆分，解读等等。
目的就是保质保量的让消息正确抵达目的地。
读过计算机网络的都知道，如果一切都正常的话是最简单的情况，但是旁枝的异常情况和各种因素的权益会让系统复杂n倍。
涉及到通信就需要考虑到一下几个因素：</p>

<ol>
<li>时间性</li>
<li>顺序性</li>
<li>会发生丢失</li>
</ol>


<p>让我们来仔细列出这个动态系统的主题：</p>

<ol>
<li>client： 动作——request，receive</li>
<li>server：动作——process，send</li>
<li>message：怎么传输——Transport模块和方法</li>
</ol>


<p>一个简单的RPC模型：
假设有echoNum一个过程，其函数形态是：
int echoNum(int num);
从上面可以知道client要发起echoNum过程调用的时候，只需给server端传输一个整形参数即可。而server端接到这个num，直接原数返回。
开始第一次调用：
echoNum(1)
我们分析我们从客户端的角度看，会产生三种结果：1.接收到了1；2.接收到了数据，但是数字不是想要的1；3.没接收到1；</p>

<p>我们再分析下有那些原因会导致这些结果（状态）：</p>

<ul>
<li>第一种情况：server接收到client请求正常，并且处理正常在一个合理的时间返回了结果。</li>
<li>第二种情况：数据发生了错误，也许client发送数据就发送错误，或许在传输过程种出错了，又或者server process过程种就错了。总之这个问题可能在图中1～4步骤都都可能。</li>
<li>第三种情况：client等了“很久”，但是数据就没有来，他也不知道哪里出问题了，所它决定不在等了，返回值设置成失败。</li>
</ul>


<p>从上面看第一种和第三种的一个关键点就在于接收到返回隐含着等待时间的问题，加入client迟迟等不到返回该采用怎样的策略。是一直等着（block），还是我先离开过段时间我再回来（sleep），还是直接永远的离去（exit）？
再复杂化一点模型，上面只牵涉到一个请求，我们现在加入多个请求：
echoNum(1)，echoNum(2)，echoNum(3)
这下我们再分析下client的返回状态有：</p>

<ul>
<li>1,2,3</li>
<li>1,3,2</li>
<li>2,1,3</li>
<li>2,3,1</li>
<li>3,1,2</li>
<li>3,2,1</li>
</ul>


<p>调用全部有返回，只是返回的时间是不确定的，所以接收到的数据也是不确定的</p>

<ul>
<li>1,2</li>
<li>1,3</li>
<li>2,1</li>
<li>2,3</li>
<li>3,1</li>
<li>3,2</li>
<li>1</li>
<li>2</li>
<li>3</li>
<li>啥也没有接收到</li>
</ul>


<p>发生了数据丢失，上面描述了丢失一个到全部丢失的全部情况。
根据实际业务需求，上面的一些结果肯定是要被剔除的，这也是RPC的调用设计种的同步和异步问题。</p>

<p>仔细学习什么<a href="http://www.cs.cf.ac.uk/Dave/C/node33.html">RPC</a></p>

<ul>
<li>RPC的基本模型和解决的问题</li>
<li>RPC框架需要注意的问题</li>
<li>RPC框架的天生缺陷和优点</li>
<li>RPC框架的使用场景和局限性</li>
<li>和RPC对应的还有那些解决框架？各自的有缺点和应用的普遍情况</li>
</ul>


<h2>thrift的定义中的特性</h2>

<p>thrift的官方定义如下：</p>

<blockquote><p>The Apache Thrift software framework, for scalable cross-language services development, combines a software stack with a code generation engine to build services that work efficiently and seamlessly between C++, Java, Python, PHP, Ruby, Erlang, Perl, Haskell, C#, Cocoa, JavaScript, Node.js, Smalltalk, OCaml and Delphi and other languages.</p></blockquote>

<p>先解释下这个定义都讲了什么。</p>

<ul>
<li>software framework：本身是一个软件框架，只提供基础的远程通信框架，意味这你自己需要补充其中的业务逻辑</li>
<li>services development：这个框架是为了辅助开发者开发出自己的一个网络服务c/s软件，而这个服务具备接下来的两个重要特点：

<ul>
<li><a href="http://www.infoq.com/cn/news/2007/10/whatisscalability">scalable 可伸缩性</a>：？？为啥说是可伸缩的？根据可伸缩的核心特征——处理能力能随这个扩展服务规模而提升。</li>
<li>cross-language 跨语言：这个可能是thrift的最大特点了，为了实现这个特性，thrift直接为此定义了一套中间语言，并且配备了一个此语言到各种目标语言的编译器。不过说起来跨语言到底指什么呢？其实一句话概括就是服务短和客户端可以是不同语言开发的，比如官方的例子：客户端是python，服务端是java。而这个中间语言就是只定义一遍服务的逻辑语义一次，通过编译器转成各种目标语言多次。从而解决重复编写的问题。</li>
</ul>
</li>
</ul>


<h2>需要的知识背景</h2>

<p>thrift的所有技能都在操作系统和计算机网络里可以找到,
推荐书籍：</p>

<ul>
<li>计算机网络</li>
<li>Unix网络编程</li>
<li>Unix系统内幕</li>
</ul>


<h2>一个简单的开发例子</h2>

<p>thrift包括其他的RPC应用的开发步骤分为下面三个步骤:</p>

<ul>
<li>定义client和server之间通信协议（protocol），即输入输出约定方式
以为一个RPC可以通过普通的函数来描述，所以协议中也必须指出函数名称，参数类型还有返回值类型。thrift根据定义好的协议来自动生成整个RPC框架，主要封装了整套的网络传输部分，剩下的部分只是业务逻辑需要开发者自己编写。控制主了远程访问的复杂度，非常棒的设计思路。</li>
<li>开发client端程序</li>
<li>开发server端程序</li>
</ul>


<h3></h3>

<h2>通信层次</h2>

<p>因为thrift更根据定义好的thrift接口，自动生成相关结构的通信层次的代码，这可算是给程序员提供了很大的便利，不过有利也有弊，你不了解，也意味着你没办法改变。
所以当出问题了，你还是需要进行深入。</p>

<h2>Reference</h2>

<ul>
<li><a href="http://blog.csdn.net/docong/article/details/6028428">thrift 白皮书</a></li>
<li><a href="https://thrift.apache.org/static/files/thrift-20070401.pdf">thrift white paper</a></li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/01/17/business-dataming-ecosystem-investigation/">Pentaho和Pivotal</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-01-17T13:55:01+08:00'><span class='date'><span class='date-month'>Jan</span> <span class='date-day'>17</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>1:55 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>接触到的关于数据处理的商业软件基本都处于pentoha和pivotal，或者总是和这两家公司有关系，所以想做个调查，报告如下：</p>

<h1><a href="http://www.pentaho.com/">Pentaho</a></h1>

<h1><a href="https://pivotal.io/">pivotal</a></h1>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/01/13/read-note-how-google-works/">Read-note: How Google Works</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-01-13T23:39:15+08:00'><span class='date'><span class='date-month'>Jan</span> <span class='date-day'>13</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>11:39 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>创意精英：
- 过硬的专业知识，懂得如何使用专业工具，还需要具备充足的实践经验
- 拥有分析头脑，可以利用数据做出决策，同时也懂得数据的误导性，从而不会沉迷其中
- 有商业头脑，知道专业技术、优质产品和商业成功是环环相扣的、也对这三个要素的价值了然于胸
- 有创造力
- 有竞争头脑，干劲十足，即使在工作之余也不停止前进的脚步
- 用户头脑，无论身处哪里行业，几乎没有人能比他们更懂得用户或消费者对产品的看法
- 自动自发，不会坐等别人为他们指出方向，对于有悖于他们信念的知识，他们会选择充耳不闻
- 心态开放，于他们自由合作，在评判构思和结论时，看重优点和而和价值而非出处</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/01/13/introduce-vertica/">介绍vertica</a></h1>
    
    
      <p class="meta">
        




<time class='entry-date' datetime='2016-01-13T18:55:49+08:00'><span class='date'><span class='date-month'>Jan</span> <span class='date-day'>13</span><span class='date-suffix'>th</span>, <span class='date-year'>2016</span></span> <span class='time'>6:55 pm</span></time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>最近olap系统开始上线vertica。话说vertica的速度真实不是盖的，太快了，完全盖过infobright的所有风采，完全不留痕迹！</p>

<h1>vertica的基本架构介绍</h1>

<p>首先定型一下vertica在数据库领域里的分支：
1. 面向批量分析数据(OLAP)
2. 关系型数据库(RDBMS)
3. 面向列式储存(column-store architechture)
4. 分布式(distributed)
按照vertica在官方文档中提到自己的特性：4 c's——<a href="https://my.vertica.com/docs/7.0.x/HTML/index.htm#Authoring/ConceptsGuide/Other/TheHPVerticaApproach.htm%3FTocPath%3DConcepts%2520Guide%7C_____1">Column Storage， Compression，Clustering，Continuous Performance</a>
其中高压缩比这个特性一般是附属于面向列式储存的特性的，不是一个正交属性。</p>

<p>当然类似于mysql，sql server等面向OLTP的数据库，其主要处理事务型数据。而vertica的设计目的已经进入到了另一个领域OLAP（OLTP和OLAP的对比，<a href="">参看这里</a>）。所以相对于OLTP大多数采用row-store的储存架构，OLAP一般会用column-store架构。<a href="">这里可以思考一下为什么会有这样的不同</a>。
上面这些都是一个成型的数据库设计架构选择。需要先了解上面提到的概念，你才可以明白为什么市场上会有如此之多的数据产品，还有vertiac的价值到底在哪里。</p>

<p>一些概念中vertica中也做了相应的变化，接下来我们来看看vertica中的一些重要概念。</p>

<h2>储存设计</h2>

<p>因为Vertica是面向列式储存的数据库，其读取也是按列为单位，其中读取实际单位是projections（作为vertica的FlexStore体系中的一个概念，假如说column-store是为了加快OLAP数据库查询速度的首选，那么FlexStore的存在就是进一步在这基础上从physical design, database storage, and query execution三个方面提升速度）。
其中打破了按表储存的架构，表在vertica中只是一个逻辑概念，其本身还是一个特殊的projections，其物理储存全部用的是projections：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>Projection
</span><span class='line'>Optimized collections of table columns that provide physical storage for data. A projection can contain some or all of the columns of one or more tables. A projection that contains all of the columns of a table is called a super-projection. A projection that joins one or more tables is called a pre-join projection.</span></code></pre></td></tr></table></div></figure>


<ul>
<li>查看projection
select node_name,wos_row_count,ros_row_count from projection_storage where anchor_table_name=&lsquo;dim_exp&rsquo;;</li>
<li>wos vs ros
<a href="http://vertica-forums.com/viewtopic.php?t=126">http://vertica-forums.com/viewtopic.php?t=126</a></li>
</ul>


<h2>如何hack</h2>

<p>上面讲了很多原理，现在我们就开始动手操作吧，俗话说说的不如做的。</p>

<h3>删除数据——分区的最大用处</h3>

<p>到底使用分区比较好呢？还是用purage_table比较好呢？
果断构建partition好，因为如果用purage对于已经转移好的ros数据块（到底会怎么样？解释不清楚了吧！）速度会很慢。<a href="https://my.vertica.com/docs/7.1.x/HTML/Content/Authoring/SQLReferenceManual/Functions/VerticaFunctions/PURGE_TABLE.htm">https://my.vertica.com/docs/7.1.x/HTML/Content/Authoring/SQLReferenceManual/Functions/VerticaFunctions/PURGE_TABLE.htm</a></p>

<h3>如何查看当前liencese的使用情况</h3>

<p>SELECT GET_COMPLIANCE_STATUS();</p>

<h3>索引到底是个什么鬼</h3>

<h3>查看执行的任务，类似于mysql的show processlist</h3>

<p>SELECT * FROM SESSIONS;</p>

<h3>数据类型</h3>

<p>在vertica中除了对int的定义不同，相比其他储存引擎，vertica的所有整形都是用64bit的，包括tinyint。
在vertica主意使用char的问题，发现当定义char(200),不满200长度的字段，会自动补全空白，这样改变了数据的内容，对于精确搜索时，这是个坑。最好改成varchar，但现在还不明白这个的性能有什么差别。</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/posts/4">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/posts/2">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2016/07/29/introduce-cap/">Introduce CAP</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/07/24/how-to-understand-a-data-system/">如何理解一个数据存储系统</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/07/23/introduce-infobright/">Introduce Infobright</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/07/20/why-need-runnable-while-we-already-have-thread-in-java/">java里为什么有了Thread还要设置一个Runnable？</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/07/18/the-world-about-oriental-column-database/">数据分析利器 —— 列式储存数据库</a>
      </li>
    
  </ul>
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2016 - Wood Carver -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  











</body>
</html>
